[
  {
    "blog": {
      "title": "Wandering Thoughts",
      "by": "Chris Siebenmann at University of Toronto",
      "url": "https://utcc.utoronto.ca/~cks/space/blog/",
      "feed": "https://utcc.utoronto.ca/~cks/space/blog/?atom",
      "description": "Fifteen years of almost daily articles on Unix/Linux and Python. Very\ninteresting findings on Unix history from a person who had experienced\nmost of it firsthand. Some less important news, scripts and\nphilosophical musings on the role of software in our lives.\n\nThe author hosts his blog at employer's hosting and domain name, so I\nwouldn't be surprised if the blog would go offline one day. Let's hope\nthe Web Archive runs its spiders regularly.",
      "section": "Linux"
    },
    "entry": {
      "id": "tag:cspace@cks.mef.org,2009-03-24:/blog/tech/MFAAccountRecoveryDistrust",
      "guidislink": true,
      "link": "https://utcc.utoronto.ca/~cks/space/blog/tech/MFAAccountRecoveryDistrust",
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://utcc.utoronto.ca/~cks/space/blog/tech/MFAAccountRecoveryDistrust"
        }
      ],
      "authors": [
        {
          "name": "cks"
        }
      ],
      "author_detail": {
        "name": "cks"
      },
      "author": "cks",
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://utcc.utoronto.ca/~cks/space/blog/?atom",
          "value": "<div class=\"wikitext\"><p>A bunch of third party websites really want you to use multi-factor\nauthentication these days. Some of them aren't giving some people\na choice about it; for example, <a href=\"https://www.bleepingcomputer.com/news/security/pypi-mandates-2fa-for-critical-projects-developer-pushes-back/\">PyPI recently mandated MFA for\nsufficiently popular projects</a>.\nI have decidedly mixed feelings about this in general, and I've\nrealized that one reason for them is that I don't trust the some\nof the potential failure modes of multi-factor authentication.\nSpecifically, the ones related to 'account recovery', also known\nas what happens when things go wrong with your MFA-related devices.</p>\n\n<p>There's no general account recovery problem with MFA. For example, if\nthe MFA hardware token from my employer was lost or destroyed, I'd\nreport it and various processes would happen and a new one would show up\nand get registered to me. If the MFA I used with my bank was lost, I'd\ngo to my bank branch to talk to them, and eventually things would get\nreset. But both of these situations have some things in common. I can\nactually talk to real people in both situations, and both have out of\nband means of identifying me (and communicating with me).</p>\n\n<p>Famously, neither of these is the case with many large third party\nwebsites, which often have functionally no customer support and\ngenerally no out of band ways of identifying you (at least not ones\nthey trust). If you (I) suffer total loss of all of your means of\ndoing MFA, you are probably completely out of luck. One consequence\nof this is that you really need to have multiple forms of MFA set\nup before you make MFA mandatory on your account (better sites will\ninsist on this). People advise things like multiple hardware tokens,\nwith some of them carefully stored offsite in trusted locations.\nThis significantly (or vastly) raises the complexity of using MFA\nwith these sites.</p>\n\n<p>More broadly, this is a balance of risks issue. I care quite a bit\nabout the availability of my accounts, and I feel that it's much\nmore likely that I will suffer from MFA issues than it is that I\nwill be targeted and successfully phished for my regular account\ncredentials (or that someone can use 'account recovery' to take\nover the account). If loss of MFA is fatal, my overall risks go way\nup if I use MFA, although the risk of account compromise goes way\ndown.</p>\n\n<p>(As a side note, this is likely not PyPI's situation. PyPI is\napparently giving people security keys, and is clearly in touch\nwith these people through additional channels. If PyPI considers\nyou and your package critical, it's very likely that you can recover\nfrom an MFA loss. PyPI here is much more like my employer than it\nis like, say, Google. But most random websites that ask me to enable\nMFA are much more like Google than PyPI.)</p>\n\n<p>(This isn't my only issue with 'you must have MFA' requirements,\nbut it's a starting point.)</p>\n</div>"
        }
      ],
      "summary": "<div class=\"wikitext\"><p>A bunch of third party websites really want you to use multi-factor\nauthentication these days. Some of them aren't giving some people\na choice about it; for example, <a href=\"https://www.bleepingcomputer.com/news/security/pypi-mandates-2fa-for-critical-projects-developer-pushes-back/\">PyPI recently mandated MFA for\nsufficiently popular projects</a>.\nI have decidedly mixed feelings about this in general, and I've\nrealized that one reason for them is that I don't trust the some\nof the potential failure modes of multi-factor authentication.\nSpecifically, the ones related to 'account recovery', also known\nas what happens when things go wrong with your MFA-related devices.</p>\n\n<p>There's no general account recovery problem with MFA. For example, if\nthe MFA hardware token from my employer was lost or destroyed, I'd\nreport it and various processes would happen and a new one would show up\nand get registered to me. If the MFA I used with my bank was lost, I'd\ngo to my bank branch to talk to them, and eventually things would get\nreset. But both of these situations have some things in common. I can\nactually talk to real people in both situations, and both have out of\nband means of identifying me (and communicating with me).</p>\n\n<p>Famously, neither of these is the case with many large third party\nwebsites, which often have functionally no customer support and\ngenerally no out of band ways of identifying you (at least not ones\nthey trust). If you (I) suffer total loss of all of your means of\ndoing MFA, you are probably completely out of luck. One consequence\nof this is that you really need to have multiple forms of MFA set\nup before you make MFA mandatory on your account (better sites will\ninsist on this). People advise things like multiple hardware tokens,\nwith some of them carefully stored offsite in trusted locations.\nThis significantly (or vastly) raises the complexity of using MFA\nwith these sites.</p>\n\n<p>More broadly, this is a balance of risks issue. I care quite a bit\nabout the availability of my accounts, and I feel that it's much\nmore likely that I will suffer from MFA issues than it is that I\nwill be targeted and successfully phished for my regular account\ncredentials (or that someone can use 'account recovery' to take\nover the account). If loss of MFA is fatal, my overall risks go way\nup if I use MFA, although the risk of account compromise goes way\ndown.</p>\n\n<p>(As a side note, this is likely not PyPI's situation. PyPI is\napparently giving people security keys, and is clearly in touch\nwith these people through additional channels. If PyPI considers\nyou and your package critical, it's very likely that you can recover\nfrom an MFA loss. PyPI here is much more like my employer than it\nis like, say, Google. But most random websites that ask me to enable\nMFA are much more like Google than PyPI.)</p>\n\n<p>(This isn't my only issue with 'you must have MFA' requirements,\nbut it's a starting point.)</p>\n</div>",
      "title": "My distrust of multi-factor authentication's account recovery story",
      "title_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://utcc.utoronto.ca/~cks/space/blog/?atom",
        "value": "My distrust of multi-factor authentication's account recovery story"
      },
      "tags": [
        {
          "term": "tech",
          "scheme": null,
          "label": null
        }
      ],
      "updated": "2022-07-11T03:32:11Z",
      "updated_parsed": [
        2022,
        7,
        11,
        3,
        32,
        11,
        0,
        192,
        0
      ],
      "published": "2022-07-11T03:31:11Z",
      "published_parsed": [
        2022,
        7,
        11,
        3,
        31,
        11,
        0,
        192,
        0
      ]
    }
  },
  {
    "blog": {
      "title": "Drew DeVault's Blog",
      "url": "https://drewdevault.com/",
      "feed": "https://drewdevault.com/blog/index.xml",
      "description": "Personal tech blog from the creator of Sourcehut, a more transparent\nalternative to GitHub.  Drew writes about being an entrepreneur in the\nFOSS world, about sustainability of Open Source projects and about\ntricky problems he uses Unix and Python knowledge to solve.",
      "section": "Linux"
    },
    "entry": {
      "title": "The Fediverse can be pretty toxic",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://drewdevault.com/blog/index.xml",
        "value": "The Fediverse can be pretty toxic"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://drewdevault.com/2022/07/09/Fediverse-toxicity.html"
        }
      ],
      "link": "https://drewdevault.com/2022/07/09/Fediverse-toxicity.html",
      "published": "Sat, 09 Jul 2022 00:00:00 +0000",
      "published_parsed": [
        2022,
        7,
        9,
        0,
        0,
        0,
        5,
        190,
        0
      ],
      "id": "https://drewdevault.com/2022/07/09/Fediverse-toxicity.html",
      "guidislink": false,
      "summary": "<p>Mastodon, inspired by GNU social, together with Pleroma, form the most popular\ncomponents of what we know as the &ldquo;Fediverse&rdquo; today. All of them are, in\nessence, federated, free software Twitter clones, interoperable with each other\nvia the ActivityPub protocol.</p>\n<p>In many respects, the Fediverse is a liberating force for good. Its federated\ndesign distributes governance and costs across many independent entities,\nsomething I view as a very strong design choice. Its moderation tools also do a\npretty good job of keeping neo-nazis out of your feeds and providing a\ncomfortable space to express yourself in, especially if your form of expression\nis maligned by society. Large groups of Fediverse members have found in it a\nhome for self-expression which is denied to them elsewhere on the basis of their\nsexuality, gender expression, politics, or other characteristics. It&rsquo;s also\nessentially entirely free from commercial propaganda.</p>\n<p>But it&rsquo;s still just a Twitter clone, and many of the social and psychological\nills which come with that are present in the Fediverse. It&rsquo;s a feed of other\npeople&rsquo;s random thoughts, often unfiltered, presented to you without value\njudgement — even when a value judgement may be wise. Features like\nboosting and liking posts, chasing after follower counts and mini-influencers,\nthese rig up dopamine reinforcement like any other social network does. The\nincreased character limit does not really help; most posts are pretty short and\nno one wants to read an essay aggressively word-wrapped in a narrow column.</p>\n<p>The Fediverse is an environment optimized for flame wars. Arguments in this\nmedium are held under these constraints, in public, with the peanut gallery of\nfollowers from either side stepping in and out to reinforce their position and\nflame the opponents. Progress is measured in gains of ideological territory and\nin the rising and falling swells of participants dotting their comments\nthroughout huge threads. You are not just arguing your position, but performing\nit to your audience, and to your opponent&rsquo;s audience.</p>\n<p>Social networks are not good for you. The Fediverse brought out the worst in me,\nand it can bring out the worst in you, too. The behaviors it encourages are\nplainly defined as harassment, a behavior which is not unique to any ideological\ncondition. People get hurt on the Fediverse. Keep that in mind. Consider taking\na look in the mirror and asking yourself if your relationship with the platform\nis healthy for you and for the people around you.</p>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://drewdevault.com/blog/index.xml",
        "value": "<p>Mastodon, inspired by GNU social, together with Pleroma, form the most popular\ncomponents of what we know as the &ldquo;Fediverse&rdquo; today. All of them are, in\nessence, federated, free software Twitter clones, interoperable with each other\nvia the ActivityPub protocol.</p>\n<p>In many respects, the Fediverse is a liberating force for good. Its federated\ndesign distributes governance and costs across many independent entities,\nsomething I view as a very strong design choice. Its moderation tools also do a\npretty good job of keeping neo-nazis out of your feeds and providing a\ncomfortable space to express yourself in, especially if your form of expression\nis maligned by society. Large groups of Fediverse members have found in it a\nhome for self-expression which is denied to them elsewhere on the basis of their\nsexuality, gender expression, politics, or other characteristics. It&rsquo;s also\nessentially entirely free from commercial propaganda.</p>\n<p>But it&rsquo;s still just a Twitter clone, and many of the social and psychological\nills which come with that are present in the Fediverse. It&rsquo;s a feed of other\npeople&rsquo;s random thoughts, often unfiltered, presented to you without value\njudgement — even when a value judgement may be wise. Features like\nboosting and liking posts, chasing after follower counts and mini-influencers,\nthese rig up dopamine reinforcement like any other social network does. The\nincreased character limit does not really help; most posts are pretty short and\nno one wants to read an essay aggressively word-wrapped in a narrow column.</p>\n<p>The Fediverse is an environment optimized for flame wars. Arguments in this\nmedium are held under these constraints, in public, with the peanut gallery of\nfollowers from either side stepping in and out to reinforce their position and\nflame the opponents. Progress is measured in gains of ideological territory and\nin the rising and falling swells of participants dotting their comments\nthroughout huge threads. You are not just arguing your position, but performing\nit to your audience, and to your opponent&rsquo;s audience.</p>\n<p>Social networks are not good for you. The Fediverse brought out the worst in me,\nand it can bring out the worst in you, too. The behaviors it encourages are\nplainly defined as harassment, a behavior which is not unique to any ideological\ncondition. People get hurt on the Fediverse. Keep that in mind. Consider taking\na look in the mirror and asking yourself if your relationship with the platform\nis healthy for you and for the people around you.</p>"
      }
    }
  },
  {
    "blog": {
      "title": "unixsheikh.com",
      "url": "http://unixsheikh.com/",
      "feed": "https://unixsheikh.com/feed.rss",
      "description": "Personal blog of old school Unix sysadmin. Pretty opinionated and\nanti-establishment. Many good articles on OpenBSD,\nnetworking/firewalling, ZFS vs other storage solutions, etc.",
      "section": "Linux"
    },
    "entry": {
      "published": "Mon, 11 Apr 2022 00:00:00 GMT",
      "published_parsed": [
        2022,
        4,
        11,
        0,
        0,
        0,
        0,
        101,
        0
      ],
      "title": "The flaws of distro hopping and asking other people about their OS of choice",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://unixsheikh.com/feed.rss",
        "value": "The flaws of distro hopping and asking other people about their OS of choice"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://unixsheikh.com/articles/the-flaws-of-distro-hopping-and-asking-other-people-about-their-os-of-choice.html"
        }
      ],
      "link": "https://unixsheikh.com/articles/the-flaws-of-distro-hopping-and-asking-other-people-about-their-os-of-choice.html",
      "id": "3cb208d5758be2eca85ce7f336082175a48f849f",
      "guidislink": false,
      "summary": "Distro hopping is a term that refers to the activity of computer users constantly installing and trying out different Linux distributions and/or BSD variants, either on bare metal or in a virtual environment, having a real difficult time choosing what to use. Some people believe that distro hopping is a result of boredom, or because of a lack of satisfaction with current choice, or that it's simply a matter of trying out multiple options, but that is not the case. Rather, it's a kind of psychological problem that arise because of a wrong approach being used in the process of determination.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://unixsheikh.com/feed.rss",
        "value": "Distro hopping is a term that refers to the activity of computer users constantly installing and trying out different Linux distributions and/or BSD variants, either on bare metal or in a virtual environment, having a real difficult time choosing what to use. Some people believe that distro hopping is a result of boredom, or because of a lack of satisfaction with current choice, or that it's simply a matter of trying out multiple options, but that is not the case. Rather, it's a kind of psychological problem that arise because of a wrong approach being used in the process of determination."
      }
    }
  },
  {
    "blog": {
      "title": "Kushal Das' Blog",
      "url": "https://kushaldas.in/",
      "feed": "https://kushaldas.in/rss.xml",
      "description": "Tech blog from a Red Hat employee, Python contributor and Fedora developer.\nGood articles on India FOSS scene, managing a LUG, privacy and security.",
      "section": "Linux"
    },
    "entry": {
      "title": "Using sigstore-python to sign and verify your software release",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://kushaldas.in/rss.xml",
        "value": "Using sigstore-python to sign and verify your software release"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://kushaldas.in/posts/using-sigstore-python-to-sign-and-verify-your-software-release.html"
        }
      ],
      "link": "https://kushaldas.in/posts/using-sigstore-python-to-sign-and-verify-your-software-release.html",
      "summary": "<!--\n.. title: Using sigstore-python to sign and verify your software release\n.. slug: using-sigstore-python-to-sign-and-verify-your-software-release\n.. date: 2022-07-05T17:41:01+02:00\n.. tags: Python, Security, OIDC, Sigstore, Fedora\n.. link:\n.. description:\n.. type: text\n-->\n<p><a href=\"https://www.sigstore.dev/\">Sigstore</a> allows software developers to quickly\nsign and verify the software they release. Many of the bigger projects use\nhardware-based OpenPGP keys to sign and release. But the steps used to make\nsure that the end-users are correctly verifying those signatures are long, and\npeople make mistakes. Also, not every project has access to hardware\nsmartcards, air-gapped private keys etc. Sigstore solves (or at least makes it\nway easier) these steps for most developers. It uses existing known (right now\nonly 3) big OIDC providers using which one can sign and verify any\ndata/software.</p>\n<p>For this blog post, I will use the python tool called <a href=\"https://github.com/sigstore/sigstore-python\">sigstore-python</a>.</p>\n<p>The first step is to create a virtual environment and then install the tool.</p>\n<pre><code>$ python3 -m venv .venv\n$ source .venv/bin/activate\n$ python -m pip install -r install/requirements.txt\n</code></pre>\n<p>Next, we create a file called <code>message.txt</code> with the data. This can be our actual release source code tarball.</p>\n<pre><code>$ echo &quot;Kushal loves Python!&quot; &gt; message.txt\n</code></pre>\n<h3>Signing the data</h3>\n<p>The next step is to actually sign the file.</p>\n<pre><code>$ python -m sigstore sign message.txt \nWaiting for browser interaction...\nUsing ephemeral certificate:\n-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----\n\nTransparency log entry created at index: 2844439\nSignature written to file message.txt.sig\nCertificate written to file message.txt.crt\n</code></pre>\n<p>The command will open up the default browser, and we will have the choice to select one of the 3 following OIDC providers.</p>\n<p><img alt=\"oidc providers\" src=\"https://kushaldas.in/images/sigstore_oidc_choice.png\" /></p>\n<p>This will also create <code>message.txt.crt</code> &amp; <code>message.txt.sig</code> files in the same directory.</p>\n<p>We can use the <code>openssl</code> command to see the contents of the certificate file.</p>\n<pre><code>$ openssl x509 -in message.txt.crt -noout -text\nCertificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number:\n            3a:c4:2d:19:20:f0:bf:85:37:a6:01:0f:49:d1:b6:39:20:06:fd:77\n        Signature Algorithm: ecdsa-with-SHA384\n        Issuer: O = sigstore.dev, CN = sigstore-intermediate\n        Validity\n            Not Before: Jul  5 14:45:23 2022 GMT\n            Not After : Jul  5 14:55:23 2022 GMT\n        Subject: \n        Subject Public Key Info:\n            Public Key Algorithm: id-ecPublicKey\n                Public-Key: (384 bit)\n                pub:\n                    04:12:aa:88:fd:c7:1f:9e:62:78:46:2a:48:63:d3:\n                    b6:92:8b:51:a4:eb:59:18:fb:18:a0:13:54:ac:d0:\n                    a4:d8:20:ab:a3:f3:5e:f5:86:aa:34:9b:30:db:59:\n                    1b:5c:3d:29:b1:5a:40:ff:55:2c:26:fc:42:58:95:\n                    53:d6:23:e5:66:90:3c:32:8c:82:b7:fc:fd:f8:28:\n                    2b:53:2d:5c:cb:df:2f:17:d0:f3:bc:26:d2:42:3d:\n                    c0:b1:55:61:50:ff:18\n                ASN1 OID: secp384r1\n                NIST CURVE: P-384\n        X509v3 extensions:\n            X509v3 Key Usage: critical\n                Digital Signature\n            X509v3 Extended Key Usage: \n                Code Signing\n            X509v3 Subject Key Identifier: \n                6C:F0:C0:63:B8:3D:BB:08:90:C3:03:45:FF:55:92:43:7D:47:19:38\n            X509v3 Authority Key Identifier: \n                DF:D3:E9:CF:56:24:11:96:F9:A8:D8:E9:28:55:A2:C6:2E:18:64:3F\n            X509v3 Subject Alternative Name: critical\n                email:mail@kushaldas.in\n            1.3.6.1.4.1.57264.1.1: \n                https://github.com/login/oauth\n            CT Precertificate SCTs: \n                Signed Certificate Timestamp:\n                    Version   : v1 (0x0)\n                    Log ID    : 08:60:92:F0:28:52:FF:68:45:D1:D1:6B:27:84:9C:45:\n                                67:18:AC:16:3D:C3:38:D2:6D:E6:BC:22:06:36:6F:72\n                    Timestamp : Jul  5 14:45:23.112 2022 GMT\n                    Extensions: none\n                    Signature : ecdsa-with-SHA256\n                                30:46:02:21:00:AB:A6:ED:59:3E:B7:C4:79:11:6A:92:\n                                29:92:BF:54:45:6A:B6:1F:6F:1C:63:7C:D9:89:26:D4:\n                                6B:EF:E3:3E:9F:02:21:00:AD:87:A7:BA:BA:7C:61:D2:\n                                53:34:E0:D0:C4:BF:6A:6E:28:B4:02:82:AA:F8:FD:0B:\n                                FB:3A:CD:B9:33:3D:F4:36\n    Signature Algorithm: ecdsa-with-SHA384\n    Signature Value:\n        30:65:02:30:17:89:76:ef:a1:0e:97:5b:a3:fe:c0:34:13:36:\n        3f:6f:2a:ba:e9:cd:bd:f2:74:d9:8c:13:2a:88:c9:96:b2:72:\n        de:34:44:95:41:f8:b0:69:5b:f0:86:a7:05:cf:81:7f:02:31:\n        00:d8:3a:12:89:39:4b:2c:ad:ff:5a:23:85:d9:c0:73:f0:b1:\n        db:5c:65:f9:5d:ee:7a:bb:b8:08:01:44:7a:2e:9f:ba:2b:4b:\n        df:6a:93:08:e9:44:2c:23:88:66:2c:f7:8f\n</code></pre>\n<h3>Verifying the signature</h3>\n<p>We can verify the signature, just make sure that the certificate &amp; signature files are in the same directory.</p>\n<pre><code>$ python -m sigstore verify message.txt \nOK: message.txt\n</code></pre>\n<p>Now, to test this with some real software releases, we will download the <code>cosign</code> RPM package and related certificate &amp; signature files. The certificate in this case, is <code>base64</code> encoded, so we decode that file first.</p>\n<pre><code>$ curl -sOL https://github.com/sigstore/cosign/releases/download/v1.9.0/cosign-1.9.0.x86_64.rpm\n$ curl -sOL https://github.com/sigstore/cosign/releases/download/v1.9.0/cosign-1.9.0.x86_64.rpm-keyless.sig\n$ curl -sOL https://github.com/sigstore/cosign/releases/download/v1.9.0/cosign-1.9.0.x86_64.rpm-keyless.pem\n$ base64 -d cosign-1.9.0.x86_64.rpm-keyless.pem &gt; cosign-1.9.0.x86_64.rpm.pem\n</code></pre>\n<p>Now let us verify the downloaded RPM package along with the <code>email</code> address and signing <code>OIDC issuer</code> URL. We are also printing the debug statements, so that\nwe can see what is actually happening for verification.</p>\n<pre><code>$ SIGSTORE_LOGLEVEL=debug python -m sigstore verify --certificate cosign-1.9.0.x86_64.rpm.pem --signature cosign-1.9.0.x86_64.rpm-keyless.sig --cert-email keyless@projectsigstore.iam.gserviceaccount.com --cert-oidc-issuer https://accounts.google.com  cosign-1.9.0.x86_64.rpm\n\nDEBUG:sigstore._cli:parsed arguments Namespace(subcommand='verify', certificate=PosixPath('cosign-1.9.0.x86_64.rpm.pem'), signature=PosixPath('cosign-1.9.0.x86_64.rpm-keyless.sig'), cert_email='keyless@projectsigstore.iam.gserviceaccount.com', cert_oidc_issuer='https://accounts.google.com', rekor_url='https://rekor.sigstore.dev', staging=False, files=[PosixPath('cosign-1.9.0.x86_64.rpm')])\nDEBUG:sigstore._cli:Using certificate from: cosign-1.9.0.x86_64.rpm.pem\nDEBUG:sigstore._cli:Using signature from: cosign-1.9.0.x86_64.rpm-keyless.sig\nDEBUG:sigstore._cli:Verifying contents from: cosign-1.9.0.x86_64.rpm\nDEBUG:sigstore._verify:Successfully verified signing certificate validity...\nDEBUG:sigstore._verify:Successfully verified signature...\nDEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): rekor.sigstore.dev:443\nDEBUG:urllib3.connectionpool:https://rekor.sigstore.dev:443 &quot;POST /api/v1/index/retrieve/ HTTP/1.1&quot; 200 69\nDEBUG:urllib3.connectionpool:https://rekor.sigstore.dev:443 &quot;GET /api/v1/log/entries/9ee91f2c5444e4ff77a3a18885f46fa2b6f7e629450904d67b5920333327b90d HTTP/1.1&quot; 200 None\nDEBUG:sigstore._verify:Successfully verified Rekor entry...\nOK: cosign-1.9.0.x86_64.rpm\n</code></pre>\n<p>Oh, one more important thing. The maintainers of the tool are amazing about\nfeedback. I had some trouble initially (a few weeks ago). They sat down with me\nto make sure that they could understand the problem &amp; also solved the issue I\nhad. You can talk to the team (and other users, including me) in the <a href=\"https://links.sigstore.dev/slack-invite\">slack room</a>.</p>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://kushaldas.in/rss.xml",
        "value": "<!--\n.. title: Using sigstore-python to sign and verify your software release\n.. slug: using-sigstore-python-to-sign-and-verify-your-software-release\n.. date: 2022-07-05T17:41:01+02:00\n.. tags: Python, Security, OIDC, Sigstore, Fedora\n.. link:\n.. description:\n.. type: text\n-->\n<p><a href=\"https://www.sigstore.dev/\">Sigstore</a> allows software developers to quickly\nsign and verify the software they release. Many of the bigger projects use\nhardware-based OpenPGP keys to sign and release. But the steps used to make\nsure that the end-users are correctly verifying those signatures are long, and\npeople make mistakes. Also, not every project has access to hardware\nsmartcards, air-gapped private keys etc. Sigstore solves (or at least makes it\nway easier) these steps for most developers. It uses existing known (right now\nonly 3) big OIDC providers using which one can sign and verify any\ndata/software.</p>\n<p>For this blog post, I will use the python tool called <a href=\"https://github.com/sigstore/sigstore-python\">sigstore-python</a>.</p>\n<p>The first step is to create a virtual environment and then install the tool.</p>\n<pre><code>$ python3 -m venv .venv\n$ source .venv/bin/activate\n$ python -m pip install -r install/requirements.txt\n</code></pre>\n<p>Next, we create a file called <code>message.txt</code> with the data. This can be our actual release source code tarball.</p>\n<pre><code>$ echo &quot;Kushal loves Python!&quot; &gt; message.txt\n</code></pre>\n<h3>Signing the data</h3>\n<p>The next step is to actually sign the file.</p>\n<pre><code>$ python -m sigstore sign message.txt \nWaiting for browser interaction...\nUsing ephemeral certificate:\n-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----\n\nTransparency log entry created at index: 2844439\nSignature written to file message.txt.sig\nCertificate written to file message.txt.crt\n</code></pre>\n<p>The command will open up the default browser, and we will have the choice to select one of the 3 following OIDC providers.</p>\n<p><img alt=\"oidc providers\" src=\"https://kushaldas.in/images/sigstore_oidc_choice.png\" /></p>\n<p>This will also create <code>message.txt.crt</code> &amp; <code>message.txt.sig</code> files in the same directory.</p>\n<p>We can use the <code>openssl</code> command to see the contents of the certificate file.</p>\n<pre><code>$ openssl x509 -in message.txt.crt -noout -text\nCertificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number:\n            3a:c4:2d:19:20:f0:bf:85:37:a6:01:0f:49:d1:b6:39:20:06:fd:77\n        Signature Algorithm: ecdsa-with-SHA384\n        Issuer: O = sigstore.dev, CN = sigstore-intermediate\n        Validity\n            Not Before: Jul  5 14:45:23 2022 GMT\n            Not After : Jul  5 14:55:23 2022 GMT\n        Subject: \n        Subject Public Key Info:\n            Public Key Algorithm: id-ecPublicKey\n                Public-Key: (384 bit)\n                pub:\n                    04:12:aa:88:fd:c7:1f:9e:62:78:46:2a:48:63:d3:\n                    b6:92:8b:51:a4:eb:59:18:fb:18:a0:13:54:ac:d0:\n                    a4:d8:20:ab:a3:f3:5e:f5:86:aa:34:9b:30:db:59:\n                    1b:5c:3d:29:b1:5a:40:ff:55:2c:26:fc:42:58:95:\n                    53:d6:23:e5:66:90:3c:32:8c:82:b7:fc:fd:f8:28:\n                    2b:53:2d:5c:cb:df:2f:17:d0:f3:bc:26:d2:42:3d:\n                    c0:b1:55:61:50:ff:18\n                ASN1 OID: secp384r1\n                NIST CURVE: P-384\n        X509v3 extensions:\n            X509v3 Key Usage: critical\n                Digital Signature\n            X509v3 Extended Key Usage: \n                Code Signing\n            X509v3 Subject Key Identifier: \n                6C:F0:C0:63:B8:3D:BB:08:90:C3:03:45:FF:55:92:43:7D:47:19:38\n            X509v3 Authority Key Identifier: \n                DF:D3:E9:CF:56:24:11:96:F9:A8:D8:E9:28:55:A2:C6:2E:18:64:3F\n            X509v3 Subject Alternative Name: critical\n                email:mail@kushaldas.in\n            1.3.6.1.4.1.57264.1.1: \n                https://github.com/login/oauth\n            CT Precertificate SCTs: \n                Signed Certificate Timestamp:\n                    Version   : v1 (0x0)\n                    Log ID    : 08:60:92:F0:28:52:FF:68:45:D1:D1:6B:27:84:9C:45:\n                                67:18:AC:16:3D:C3:38:D2:6D:E6:BC:22:06:36:6F:72\n                    Timestamp : Jul  5 14:45:23.112 2022 GMT\n                    Extensions: none\n                    Signature : ecdsa-with-SHA256\n                                30:46:02:21:00:AB:A6:ED:59:3E:B7:C4:79:11:6A:92:\n                                29:92:BF:54:45:6A:B6:1F:6F:1C:63:7C:D9:89:26:D4:\n                                6B:EF:E3:3E:9F:02:21:00:AD:87:A7:BA:BA:7C:61:D2:\n                                53:34:E0:D0:C4:BF:6A:6E:28:B4:02:82:AA:F8:FD:0B:\n                                FB:3A:CD:B9:33:3D:F4:36\n    Signature Algorithm: ecdsa-with-SHA384\n    Signature Value:\n        30:65:02:30:17:89:76:ef:a1:0e:97:5b:a3:fe:c0:34:13:36:\n        3f:6f:2a:ba:e9:cd:bd:f2:74:d9:8c:13:2a:88:c9:96:b2:72:\n        de:34:44:95:41:f8:b0:69:5b:f0:86:a7:05:cf:81:7f:02:31:\n        00:d8:3a:12:89:39:4b:2c:ad:ff:5a:23:85:d9:c0:73:f0:b1:\n        db:5c:65:f9:5d:ee:7a:bb:b8:08:01:44:7a:2e:9f:ba:2b:4b:\n        df:6a:93:08:e9:44:2c:23:88:66:2c:f7:8f\n</code></pre>\n<h3>Verifying the signature</h3>\n<p>We can verify the signature, just make sure that the certificate &amp; signature files are in the same directory.</p>\n<pre><code>$ python -m sigstore verify message.txt \nOK: message.txt\n</code></pre>\n<p>Now, to test this with some real software releases, we will download the <code>cosign</code> RPM package and related certificate &amp; signature files. The certificate in this case, is <code>base64</code> encoded, so we decode that file first.</p>\n<pre><code>$ curl -sOL https://github.com/sigstore/cosign/releases/download/v1.9.0/cosign-1.9.0.x86_64.rpm\n$ curl -sOL https://github.com/sigstore/cosign/releases/download/v1.9.0/cosign-1.9.0.x86_64.rpm-keyless.sig\n$ curl -sOL https://github.com/sigstore/cosign/releases/download/v1.9.0/cosign-1.9.0.x86_64.rpm-keyless.pem\n$ base64 -d cosign-1.9.0.x86_64.rpm-keyless.pem &gt; cosign-1.9.0.x86_64.rpm.pem\n</code></pre>\n<p>Now let us verify the downloaded RPM package along with the <code>email</code> address and signing <code>OIDC issuer</code> URL. We are also printing the debug statements, so that\nwe can see what is actually happening for verification.</p>\n<pre><code>$ SIGSTORE_LOGLEVEL=debug python -m sigstore verify --certificate cosign-1.9.0.x86_64.rpm.pem --signature cosign-1.9.0.x86_64.rpm-keyless.sig --cert-email keyless@projectsigstore.iam.gserviceaccount.com --cert-oidc-issuer https://accounts.google.com  cosign-1.9.0.x86_64.rpm\n\nDEBUG:sigstore._cli:parsed arguments Namespace(subcommand='verify', certificate=PosixPath('cosign-1.9.0.x86_64.rpm.pem'), signature=PosixPath('cosign-1.9.0.x86_64.rpm-keyless.sig'), cert_email='keyless@projectsigstore.iam.gserviceaccount.com', cert_oidc_issuer='https://accounts.google.com', rekor_url='https://rekor.sigstore.dev', staging=False, files=[PosixPath('cosign-1.9.0.x86_64.rpm')])\nDEBUG:sigstore._cli:Using certificate from: cosign-1.9.0.x86_64.rpm.pem\nDEBUG:sigstore._cli:Using signature from: cosign-1.9.0.x86_64.rpm-keyless.sig\nDEBUG:sigstore._cli:Verifying contents from: cosign-1.9.0.x86_64.rpm\nDEBUG:sigstore._verify:Successfully verified signing certificate validity...\nDEBUG:sigstore._verify:Successfully verified signature...\nDEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): rekor.sigstore.dev:443\nDEBUG:urllib3.connectionpool:https://rekor.sigstore.dev:443 &quot;POST /api/v1/index/retrieve/ HTTP/1.1&quot; 200 69\nDEBUG:urllib3.connectionpool:https://rekor.sigstore.dev:443 &quot;GET /api/v1/log/entries/9ee91f2c5444e4ff77a3a18885f46fa2b6f7e629450904d67b5920333327b90d HTTP/1.1&quot; 200 None\nDEBUG:sigstore._verify:Successfully verified Rekor entry...\nOK: cosign-1.9.0.x86_64.rpm\n</code></pre>\n<p>Oh, one more important thing. The maintainers of the tool are amazing about\nfeedback. I had some trouble initially (a few weeks ago). They sat down with me\nto make sure that they could understand the problem &amp; also solved the issue I\nhad. You can talk to the team (and other users, including me) in the <a href=\"https://links.sigstore.dev/slack-invite\">slack room</a>.</p>"
      },
      "id": "https://kushaldas.in/posts/using-sigstore-python-to-sign-and-verify-your-software-release.html",
      "guidislink": false,
      "published": "Tue, 05 Jul 2022 17:41:01 +0200",
      "published_parsed": [
        2022,
        7,
        5,
        15,
        41,
        1,
        1,
        186,
        0
      ]
    }
  },
  {
    "blog": {
      "title": "Xe Iaso (Christine Dodrill)",
      "url": "https://xeiaso.net/blog",
      "feed": "https://xeiaso.net/blog.rss",
      "description": "NixOS and k8s in a homelab. Some deployment walkthroughs, some high-level\noverviews of tech concepts - all in a monospace font with anime characters\nin sidebars.",
      "section": "Linux"
    },
    "entry": {
      "id": "https://xeiaso.net/blog/spearphishing",
      "guidislink": true,
      "link": "https://xeiaso.net/blog/spearphishing",
      "title": "Spearphishing: it can happen to you too",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://xeiaso.net/blog.rss",
        "value": "Spearphishing: it can happen to you too"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://xeiaso.net/blog/spearphishing"
        }
      ],
      "summary": "<p><figure class=\"hero\" style=\"margin: 0;\"><source type=\"image/avif\" /><source type=\"image/webp\" /><img alt=\"hero image the-fool\" src=\"https://cdn.xeiaso.net/file/christine-static/hero/the-fool-smol.png\" style=\"padding: 0;\" /><figcaption>Image generated by MidJourney -- The Fool in a woodcut tarot card style</figcaption></figure></p>\n<p>For some reason, LinkedIn has become the de-facto social network for\nprofessionals. It is viewed as a powerful networking and marketing site that\nlets professionals communicate, find new opportunities and source talent at\neye-watering speed and rates. However, at the same time this also means that\nLinkedIn becomes a treasure trove of data to enable spearphising attacks.</p>\n<p>Let's consider <a href=\"https://www.theblock.co/post/156038/how-a-fake-job-offer-took-down-the-worlds-most-popular-crypto-game\">this attack against popular &quot;play to earn&quot; game Axie\nInfinity</a>.\nThe attackers had PDF based malware that allowed them to get access to a target\ncomputer, so they needed someone to open a PDF to trigger the exploit chain that\nlet them gain a foothold. But they specifically wanted people that likely had\naccess to the crypto wallets that enable control of the blockchain. LinkedIn let\nthem filter by employees at the company behind Axie Infinity that were\ndevelopers and likely started spearphishing by role and seniority. The details\nof the attack spell out that the attackers had set up a whole fake interview\nprocess to convince the marks that the process was legitimate and they put the\nmalware in the offer letter. The attackers later gained access to the validator\nwallets and then they were able to make off with over half a billion dollars\nworth of cryptocurrency.</p>\n<p>\n<div class=\"conversation\">\n    <div class=\"conversation-picture conversation-smol\">\n        \n            <source type=\"image/avif\" />\n            <source type=\"image/webp\" />\n            <img alt=\"Numa is delet\" src=\"https://cdn.xeiaso.net/file/christine-static/stickers/numa/delet.png\" />\n        \n    </div>\n    <div class=\"conversation-chat\">&lt;<b>Numa</b>&gt; Maybe, just maybe you shouldn't store a\nmajority of the keys required to validate something on <em>the same computer</em>.\nEspecially if those keypairs control assets worth close to <em>half a billion\ndollars</em>. Holy heck.</div></div></p>\n<p>The malware was in the offer letter. This is the kind of social engineering\nattack that I bet any one of you reading this article could fall for. Hell, I'd\nprobably fall for this. This may be the wrong kind of take to have, but I'm\nreally starting to wonder if using LinkedIn so much is actually bad for\nsecurity. It's not just recruiters reading through LinkedIn anymore, it's also\nthreat actors that are trying to break in and do God knows what. Maybe we as an\nindustry should stop feeding all of that data into LinkedIn. Not only would it\ngive you less recruiter spam, maybe it'll make spearphishing attacks more\ndifficult too.</p>\n<p>\n<div class=\"conversation\">\n    <div class=\"conversation-picture conversation-smol\">\n        \n            <source type=\"image/avif\" />\n            <source type=\"image/webp\" />\n            <img alt=\"Cadey is coffee\" src=\"https://cdn.xeiaso.net/file/christine-static/stickers/cadey/coffee.png\" />\n        \n    </div>\n    <div class=\"conversation-chat\">&lt;<b>Cadey</b>&gt; Also, yes we can't trust PDFs anymore,\nespecially after exploits like\n<a href=\"https://googleprojectzero.blogspot.com/2021/12/a-deep-dive-into-nso-zero-click.html\">FORCEDENTRY</a>\nbecame a thing.</div></div></p>\n<p>Either way, I may end up getting a disposable machine for dealing with reading\nPDFs from unknown sources in the future. I could use a virtual machine for this,\nbut if my threat model includes PDFs having exploits in them then I probably\ncan't trust a virtual machine to be a reasonable security barrier. I don't know.\nIt sucks that we can't trust people anymore.</p>\n<p>I kinda wish we could.</p>\n<hr />\n<p>\n<div class=\"conversation\">\n    <div class=\"conversation-picture conversation-smol\">\n        \n            <source type=\"image/avif\" />\n            <source type=\"image/webp\" />\n            <img alt=\"Mara is hacker\" src=\"https://cdn.xeiaso.net/file/christine-static/stickers/mara/hacker.png\" />\n        \n    </div>\n    <div class=\"conversation-chat\">&lt;<b>Mara</b>&gt; Fun fact: the tarot card &quot;The Fool&quot;\ndoesn't actually imply idiocy in a malicious way. The major arcana of the tarot\nis a bunch of memes that describe the story of The Fool's journey through magick\nand learning how the world works. The Fool is not an idiot, The Fool is just\nsomeone that is unaware of the difficulties they are going to face in life and\ntreats things optimistically. Think a free spirit as opposed to someone that is\nfoolhardy (though foolhardiness is the meaning of The Fool when the card is\ninverted).</div></div></p>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://xeiaso.net/blog.rss",
        "value": "<p><figure class=\"hero\" style=\"margin: 0;\"><source type=\"image/avif\" /><source type=\"image/webp\" /><img alt=\"hero image the-fool\" src=\"https://cdn.xeiaso.net/file/christine-static/hero/the-fool-smol.png\" style=\"padding: 0;\" /><figcaption>Image generated by MidJourney -- The Fool in a woodcut tarot card style</figcaption></figure></p>\n<p>For some reason, LinkedIn has become the de-facto social network for\nprofessionals. It is viewed as a powerful networking and marketing site that\nlets professionals communicate, find new opportunities and source talent at\neye-watering speed and rates. However, at the same time this also means that\nLinkedIn becomes a treasure trove of data to enable spearphising attacks.</p>\n<p>Let's consider <a href=\"https://www.theblock.co/post/156038/how-a-fake-job-offer-took-down-the-worlds-most-popular-crypto-game\">this attack against popular &quot;play to earn&quot; game Axie\nInfinity</a>.\nThe attackers had PDF based malware that allowed them to get access to a target\ncomputer, so they needed someone to open a PDF to trigger the exploit chain that\nlet them gain a foothold. But they specifically wanted people that likely had\naccess to the crypto wallets that enable control of the blockchain. LinkedIn let\nthem filter by employees at the company behind Axie Infinity that were\ndevelopers and likely started spearphishing by role and seniority. The details\nof the attack spell out that the attackers had set up a whole fake interview\nprocess to convince the marks that the process was legitimate and they put the\nmalware in the offer letter. The attackers later gained access to the validator\nwallets and then they were able to make off with over half a billion dollars\nworth of cryptocurrency.</p>\n<p>\n<div class=\"conversation\">\n    <div class=\"conversation-picture conversation-smol\">\n        \n            <source type=\"image/avif\" />\n            <source type=\"image/webp\" />\n            <img alt=\"Numa is delet\" src=\"https://cdn.xeiaso.net/file/christine-static/stickers/numa/delet.png\" />\n        \n    </div>\n    <div class=\"conversation-chat\">&lt;<b>Numa</b>&gt; Maybe, just maybe you shouldn't store a\nmajority of the keys required to validate something on <em>the same computer</em>.\nEspecially if those keypairs control assets worth close to <em>half a billion\ndollars</em>. Holy heck.</div></div></p>\n<p>The malware was in the offer letter. This is the kind of social engineering\nattack that I bet any one of you reading this article could fall for. Hell, I'd\nprobably fall for this. This may be the wrong kind of take to have, but I'm\nreally starting to wonder if using LinkedIn so much is actually bad for\nsecurity. It's not just recruiters reading through LinkedIn anymore, it's also\nthreat actors that are trying to break in and do God knows what. Maybe we as an\nindustry should stop feeding all of that data into LinkedIn. Not only would it\ngive you less recruiter spam, maybe it'll make spearphishing attacks more\ndifficult too.</p>\n<p>\n<div class=\"conversation\">\n    <div class=\"conversation-picture conversation-smol\">\n        \n            <source type=\"image/avif\" />\n            <source type=\"image/webp\" />\n            <img alt=\"Cadey is coffee\" src=\"https://cdn.xeiaso.net/file/christine-static/stickers/cadey/coffee.png\" />\n        \n    </div>\n    <div class=\"conversation-chat\">&lt;<b>Cadey</b>&gt; Also, yes we can't trust PDFs anymore,\nespecially after exploits like\n<a href=\"https://googleprojectzero.blogspot.com/2021/12/a-deep-dive-into-nso-zero-click.html\">FORCEDENTRY</a>\nbecame a thing.</div></div></p>\n<p>Either way, I may end up getting a disposable machine for dealing with reading\nPDFs from unknown sources in the future. I could use a virtual machine for this,\nbut if my threat model includes PDFs having exploits in them then I probably\ncan't trust a virtual machine to be a reasonable security barrier. I don't know.\nIt sucks that we can't trust people anymore.</p>\n<p>I kinda wish we could.</p>\n<hr />\n<p>\n<div class=\"conversation\">\n    <div class=\"conversation-picture conversation-smol\">\n        \n            <source type=\"image/avif\" />\n            <source type=\"image/webp\" />\n            <img alt=\"Mara is hacker\" src=\"https://cdn.xeiaso.net/file/christine-static/stickers/mara/hacker.png\" />\n        \n    </div>\n    <div class=\"conversation-chat\">&lt;<b>Mara</b>&gt; Fun fact: the tarot card &quot;The Fool&quot;\ndoesn't actually imply idiocy in a malicious way. The major arcana of the tarot\nis a bunch of memes that describe the story of The Fool's journey through magick\nand learning how the world works. The Fool is not an idiot, The Fool is just\nsomeone that is unaware of the difficulties they are going to face in life and\ntreats things optimistically. Think a free spirit as opposed to someone that is\nfoolhardy (though foolhardiness is the meaning of The Fool when the card is\ninverted).</div></div></p>"
      },
      "published": "Sat, 09 Jul 2022 00:00:00 +0000",
      "published_parsed": [
        2022,
        7,
        9,
        0,
        0,
        0,
        5,
        190,
        0
      ]
    }
  },
  {
    "blog": {
      "title": "blog.kroy.io",
      "url": "https://blog.kroy.io/",
      "feed": "https://blog.kroy.io/feed/",
      "description": "Homelab enthusiast with a lot of informative writeups on hypervisors,\nautomation and routing. Lots of routing! BGP, VyOS, router benchmarks - the\nfun stuff!",
      "section": "Homelab"
    },
    "entry": {
      "title": "VyOS and Mikrotik – VLAN-a-rama",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blog.kroy.io/feed/",
        "value": "VyOS and Mikrotik – VLAN-a-rama"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blog.kroy.io/2021/06/29/vyos-and-mikrotik-vlan-a-rama/?utm_source=rss&utm_medium=rss&utm_campaign=vyos-and-mikrotik-vlan-a-rama"
        }
      ],
      "link": "https://blog.kroy.io/2021/06/29/vyos-and-mikrotik-vlan-a-rama/?utm_source=rss&utm_medium=rss&utm_campaign=vyos-and-mikrotik-vlan-a-rama",
      "authors": [
        {
          "name": "Kroy"
        }
      ],
      "author": "Kroy",
      "author_detail": {
        "name": "Kroy"
      },
      "published": "Tue, 29 Jun 2021 19:12:19 +0000",
      "published_parsed": [
        2021,
        6,
        29,
        19,
        12,
        19,
        1,
        180,
        0
      ],
      "tags": [
        {
          "term": "mikrotik",
          "scheme": null,
          "label": null
        },
        {
          "term": "Networking",
          "scheme": null,
          "label": null
        },
        {
          "term": "VyOS",
          "scheme": null,
          "label": null
        },
        {
          "term": "VLAN",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blog.kroy.io/?p=1169",
      "guidislink": false,
      "summary": "For the novice networker, VLANs are easily one of the most misunderstood concepts. In this post, I&#8217;ll go over some basics and demonstrate how to make the jump from separate&#8230;",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blog.kroy.io/feed/",
        "value": "For the novice networker, VLANs are easily one of the most misunderstood concepts. In this post, I&#8217;ll go over some basics and demonstrate how to make the jump from separate&#8230;"
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blog.kroy.io/feed/",
          "value": "<p>For the novice networker, VLANs are easily one of the most misunderstood concepts.  In this post, I&#8217;ll go over some basics and demonstrate how to make the jump from separate interfaces and switches to VLANs. </p>\n\n\n\n<hr class=\"wp-block-separator\" />\n\n\n\n\n\n<hr class=\"wp-block-separator\" />\n\n\n\n<h2>Introduction</h2>\n\n\n\n<p>Virtual LANs, or VLANs, are one of the most useful features in all of networking.  To put it simply, they allow a logical separation of broadcast domains.  In layperson&#8217;s terms, &#8220;I took a switch and put it in your switch!&#8221;.  </p>\n\n\n\n<p>I think it&#8217;s best to start with a traditional physical setup that would represent how most people start their networking adventures.</p>\n\n\n\n<hr class=\"wp-block-separator\" />\n\n\n\n<h2>Physical Setup</h2>\n\n\n\n<p>For this adventure, I&#8217;ll be using be using:</p>\n\n\n\n<ul><li>The <a href=\"https://blog.kroy.io/2020/01/17/the-baby-wyse-the-dell-3040/\" rel=\"noreferrer noopener\" target=\"_blank\">WYSE 3040</a> from a previous blog post.</li><li>An array of small Mikrotiks (<a href=\"https://amzn.to/35XStKu\" rel=\"noreferrer noopener\" target=\"_blank\">hex</a>, <a href=\"https://amzn.to/3AefB5h\">hap</a>, <a href=\"https://amzn.to/2UR3I5h\" rel=\"noreferrer noopener\" target=\"_blank\">hex lite</a>) since they are painfully easy to set up as both simple switches and managed switches supporting VLANs.</li><li>A few Virtual Machines to act as end devices, also from a<a href=\"https://blog.kroy.io/2021/06/23/vyos-from-scratch-routing-and-vps-edition/\"> prior blog post.</a></li></ul>\n\n\n\n<p>Let&#8217;s start with this simple network diagram.  </p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img alt=\"\" class=\"wp-image-1221\" height=\"902\" src=\"https://blog.kroy.io/wp-content/uploads/2021/06/vlanaram1-1.png\" width=\"651\" /><figcaption>physical layout</figcaption></figure></div>\n\n\n\n<p>and how does this setup look when it&#8217;s all wired up?</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img alt=\"\" class=\"wp-image-1232\" height=\"768\" src=\"https://blog.kroy.io/wp-content/uploads/2021/06/IMG_0491-1024x768.jpg\" width=\"1024\" /><figcaption>messy</figcaption></figure></div>\n\n\n\n<hr class=\"wp-block-separator\" />\n\n\n\n<h3>Networking Config</h3>\n\n\n\n<p>This is the basic config for all three of the switches.  I don&#8217;t want to get too bogged down with the Mikrotik config, but I should explain some of it.</p>\n\n\n\n<p>In the Linux world, and subsequently in Mikrotik-land, a switch would be called a &#8220;bridge&#8221;.  So in this case, I&#8217;ve created a bridge and added all the ports to it.  And then I&#8217;ve told the switches to pull an IP address from the bridge for management.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&#091;admin@MikroTik] &gt; /export \n# jun/28/2021 21:03:30 by RouterOS 6.48.3\n# software id = IMPN-EEMU\n#\n# model = RB750Gr3\n\n/interface bridge\nadd admin-mac=B8:69:F4:AB:2E:7A auto-mac=no comment=defconf name=bridgeLocal\n/interface bridge port\nadd bridge=bridgeLocal comment=defconf interface=ether1\nadd bridge=bridgeLocal comment=defconf interface=ether2\nadd bridge=bridgeLocal comment=defconf interface=ether3\nadd bridge=bridgeLocal comment=defconf interface=ether4\nadd bridge=bridgeLocal comment=defconf interface=ether5\n/ip dhcp-client\nadd comment=defconf disabled=no interface=bridgeLocal\n</code></pre>\n\n\n\n<p>This configuration essentially turns these Mikrotik devices into a dumb switch, with an IP address to manage them.  They are also plugged into my existing network:</p>\n\n\n\n<ul><li>HEX into my &#8220;WAN&#8221; network (random VLAN on my existing network that has internet access)</li><li>HAP into a VLAN connected to the &#8220;enduser1&#8221; VM </li><li>HEX LITE into a VLAN connected to the &#8220;enduser2&#8221; VM.</li></ul>\n\n\n\n<p> </p>\n\n\n\n<hr class=\"wp-block-separator\" />\n\n\n\n<h3>VyOS Config</h3>\n\n\n\n<p>The VyOS config here on the WYSE 3040 is very simple:</p>\n\n\n\n<ul><li>Onboard NIC is eth0, connected to WAN/HEX switch, pulling an IP from my existing infrastructure.</li><li>USB NIC1 is eth1, connected to HAP switch</li><li>USB NIC2 is eth2, connected to HEX switch</li><li>Some NAT, so my test clients can get on the Internet</li><li>Some DHCP, so my test clients can auto-configure themselves</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>interfaces {\n    ethernet eth0 {\n        address dhcp\n        description WAN\n        hw-id 8c:ec:4b:6d:dc:d6\n    }\n    ethernet eth1 {\n        address 172.21.39.1/24\n        description HAPLAN\n        hw-id 8c:ae:4c:f5:e5:8f\n    }\n    ethernet eth2 {\n        address 192.168.39.1/24\n        description HEXLITELAN\n        hw-id 8c:ae:4c:f5:e5:94\n    }\n    loopback lo {\n    }\n}\nnat {\n    source {\n        rule 10 {\n            outbound-interface eth0\n            source {\n                address 172.21.39.0/24\n            }\n            translation {\n                address masquerade\n            }\n        }\n        rule 11 {\n            outbound-interface eth0\n            source {\n                address 192.168.39.0/24\n            }\n            translation {\n                address masquerade\n            }\n        }\n    }\n}\nservice {\n    dhcp-server {\n        shared-network-name HAPDHCP {\n            subnet 172.21.39.0/24 {\n                default-router 172.21.39.1\n                dns-server 10.53.53.53\n                range 0 {\n                    start 172.21.39.100\n                    stop 172.21.39.200\n                }\n            }\n        }\n        shared-network-name HEXLITEDHCP {\n            subnet 192.168.39.0/24 {\n                default-router 192.168.39.1\n                dns-server 10.53.53.53\n                range 0 {\n                    start 192.168.39.100\n                    stop 192.168.39.200\n                }\n            }\n        }\n    }\n    ssh {\n        port 22\n    }\n}</code></pre>\n\n\n\n<p>And once it&#8217;s all set up, the two &#8220;enduser&#8221; VMs both have appropriate IP addresses and Internet access as served out by the VyOS-3040:</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1216\" height=\"328\" src=\"https://blog.kroy.io/wp-content/uploads/2021/06/image-47-1024x328.png\" width=\"1024\" /><figcaption>VMs working</figcaption></figure>\n\n\n\n<hr class=\"wp-block-separator\" />\n\n\n\n<h2>VLANs</h2>\n\n\n\n<p>Of course we aren&#8217;t here to just make a simple multi-network setup.  We want some VLANs.  So let&#8217;s rewrite some things, and eliminate two of the switches. </p>\n\n\n\n<p>First off, let&#8217;s talk about the physical setup we had before.  Before, each of the different switches were connected to &#8220;raw&#8221; ports connecting to existing VLANs on my network:</p>\n\n\n\n<ul><li>HEX: VAN9.  This is an existing client network in my homelab.  You plug something in here, it gets a 10.9.1.0/24 address, and instantly has Internet access. This is what the &#8220;WAN&#8221; port of VyOS connects to.</li><li>HAP: VLAN41.  This was a new VLAN I created to connect between eth1 on VyOS and the &#8220;enduser1&#8221; VM.</li><li>HEX LITE: VLAN42. Similarly, a new VLAN I created to connect between eth2 on VyOS and the &#8220;enduser2&#8221; VM.</li></ul>\n\n\n\n<p>Physically, this is how the new setup will look:</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img alt=\"\" class=\"wp-image-1234\" height=\"1024\" src=\"https://blog.kroy.io/wp-content/uploads/2021/06/IMG_0494-768x1024.jpg\" width=\"768\" /><figcaption>getting cleaner</figcaption></figure></div>\n\n\n\n<p>In most networking circles, a &#8220;trunk&#8221; just means a port carrying multiple VLANs.  Since we removed two switches, the remaining switch, the HEX, will need to have its uplink port changed into a trunk:</p>\n\n\n\n<ul><li>Remove HAP and HEX LITE switches</li><li>On the HEX, change the port that was previously connected to a raw VLAN9 port on my existing network to a trunk.</li><li>Plug eth1 from VyOS into port 4 on HEX, change the VLAN of that port to 41</li><li>Plug eth2 from VyOS into port 3 on HEX, change the VLAN of the port to 42</li><li>Change the VLAN on port 5 on the HEX to 9.  This will change the PVID, or the raw VLAN that&#8217;s use when whatever is plugged in on the other end isn&#8217;t speaking VLANs.</li><li>Due to the prior step, the nothing on VyOS will change</li></ul>\n\n\n\n<p>The characteristics of our trunk ports will be simple:</p>\n\n\n\n<ul><li>VLAN1 == PVID/untagged.  This is the VLAN traffic will land on if the traffic has no VLAN tags</li><li>VLAN9 == Tagged. </li><li>VLAN41 == Tagged</li><li>VLAN42 == Tagged</li></ul>\n\n\n\n<p>I&#8217;ve highlighted the important changes on the remaining switch below:</p>\n\n\n\n<ol><li>Add an Switched Virtual Interface or SVI.  This is saying &#8220;Give this switch an interface on this VLAN&#8221;.  This is important because VLAN9 is no longer the default &#8220;untagged&#8221; for the uplink port (ether1)</li><li>Change the PVIDs/default VLANs of the appropriate ports on the bridge.  We are doing this to make the VyOS-3040 think nothing has changed in our physical setup.</li><li>Handle VLAN filtering.  This is going to control what VLANs are allowed on these ports. This is how you create a trunk port in Mikrotik <ol><li><code>ether1</code> is the Trunk to the rest of the network.  It is untagged on VLAN1 (which is a throwaway VLAN for security).  It is tagged on the other two VLANs we are using, 41 and 42.</li><li><code>bridgeLocal</code> is Mikrotik itself. It is untagged on VLAN1 for similar reasons as above.  It it tagged on VLAN9 as this is what allows our newly created <code>VLAN9_SVI</code> so we can create a management address for it.</li><li><code>ether3/4/5</code> are all untagged on the VLANs that match the PVIDs.</li></ol></li><li>Finally, we tell the Mikrotik to pull its address via DHCP on the newly created <code>VLAN9_SVI</code></li></ol>\n\n\n\n<pre class=\"wp-block-code\"><code># jun/29/2021 10:27:41 by RouterOS 6.48.3\n# software id = IMPN-EEMU\n#\n# model = RB750Gr3\n\n/interface bridge\nadd admin-mac=B8:69:F4:AB:2E:7A auto-mac=no comment=defconf name=bridgeLocal vlan-filtering=yes\n<strong>/interface vlan\nadd interface=bridgeLocal name=VLAN9_SVI vlan-id=9</strong>\n/interface bridge port\nadd bridge=bridgeLocal comment=defconf interface=ether1\nadd bridge=bridgeLocal comment=defconf interface=ether2\n<strong>add bridge=bridgeLocal comment=defconf interface=ether3 pvid=42\nadd bridge=bridgeLocal comment=defconf interface=ether4 pvid=41\nadd bridge=bridgeLocal comment=defconf interface=ether5 pvid=9</strong>\n/interface bridge vlan\n<strong>add bridge=bridgeLocal untagged=bridgeLocal,ether1 vlan-ids=1</strong>\n<strong>add bridge=bridgeLocal tagged=bridgeLocal,ether1 untagged=ether5 vlan-ids=9\nadd bridge=bridgeLocal tagged=ether1 untagged=ether4 vlan-ids=41\nadd bridge=bridgeLocal tagged=ether1 untagged=ether3 vlan-ids=42</strong>\n/ip dhcp-client\n<strong>add comment=defconf disabled=no interface=VLAN9_SVI</strong></code></pre>\n\n\n\n<p>As mentioned above, everything just works as before.  As far as the VyOS-3040 is concerned, it is still connected to three separate switches:</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1217\" height=\"327\" src=\"https://blog.kroy.io/wp-content/uploads/2021/06/image-48-1024x327.png\" width=\"1024\" /><figcaption>as before, working perfect</figcaption></figure>\n\n\n\n<h2>VLANs &#8211; Going Deeper</h2>\n\n\n\n<p>Of course, we haven&#8217;t even touched VLANs on VyOS yet, so let&#8217;s dig into that.  </p>\n\n\n\n<p>The basic goals will be:</p>\n\n\n\n<ul><li>Remove all the dongles</li><li>Move the cable that goes to VyOS-3040 from port 5 to port 2.</li><li>Trunk VLANs 41 and 42 into VyOS</li><li>Change the config in VyOS to use VLAN interfaces instead of physical interfaces.</li></ul>\n\n\n\n<p>Physically, this is starting to look super clean.  We only have two cables plugged into the switch, the trunk from the existing networking and the trunk to the VyOS-3040. </p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img alt=\"\" class=\"wp-image-1223\" height=\"1024\" src=\"https://blog.kroy.io/wp-content/uploads/2021/06/image-50-659x1024.png\" width=\"659\" /><figcaption>cleaner still</figcaption></figure></div>\n\n\n\n<p>I&#8217;ve highlighted the changes to the switch, but basically we are turning port 2 into another trunk, BUUUUT, a trunk with the PVID of 9:</p>\n\n\n\n<ul><li>Change the PVID of ether2 to 9.  This is to make it so VyOS-3040 still is &#8220;on&#8221; VLAN9 on its raw port</li><li>Add ether2 as untagged on VLAN9</li><li>Add ether2 as tagged on VLANs 41/42</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code># jun/29/2021 10:49:20 by RouterOS 6.48.3\n# software id = IMPN-EEMU\n#\n# model = RB750Gr3\n# serial number = 8AFF09A3F98D\n/interface bridge\nadd admin-mac=B8:69:F4:AB:2E:7A auto-mac=no comment=defconf name=bridgeLocal vlan-filtering=yes\n/interface vlan\nadd interface=bridgeLocal name=VLAN9_SVI vlan-id=9\n/interface bridge port\nadd bridge=bridgeLocal comment=defconf interface=ether1\n<strong>add bridge=bridgeLocal comment=defconf interface=ether2 pvid=9</strong>\nadd bridge=bridgeLocal comment=defconf interface=ether3 pvid=42\nadd bridge=bridgeLocal comment=defconf interface=ether4 pvid=41\nadd bridge=bridgeLocal comment=defconf interface=ether5 pvid=9\n/ip neighbor discovery-settings\nset discover-interface-list=!dynamic\n/interface bridge vlan\nadd bridge=bridgeLocal untagged=bridgeLocal,ether1 vlan-ids=1\n<strong>add bridge=bridgeLocal tagged=bridgeLocal,ether1 untagged=ether5,ether2 vlan-ids=9</strong>\n<strong>add bridge=bridgeLocal tagged=ether1,ether2 untagged=ether4 vlan-ids=41\nadd bridge=bridgeLocal tagged=ether1,ether2 untagged=ether3 vlan-ids=42</strong>\n/ip dhcp-client\nadd comment=defconf disabled=no interface=VLAN9_SVI</code></pre>\n\n\n\n<p>And in VyOS, the only change is removing eth1/eth2, and moving the config under the appropriate vif:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>interfaces {\n    ethernet eth0 {\n        address dhcp\n        description WAN\n        hw-id 8c:ec:4b:6d:dc:d6\n        <strong>vif 41 {\n            address 172.21.39.1/24\n            description HAPLAN\n        }\n        vif 42 {\n            address 192.168.39.1/24\n            description HEXLITELAN\n        }</strong>\n    }\n    loopback lo {\n    }\n}\n</code></pre>\n\n\n\n<p>which we can now access everywhere via <code>eth0.41</code>/<code>eth0.42</code>.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>vyos@vyos:~$ show interfaces \nCodes: S - State, L - Link, u - Up, D - Down, A - Admin Down\nInterface        IP Address                        S/L  Description\n---------        ----------                        ---  -----------\neth0             10.9.1.73/24                      u/u  WAN   \neth0.41          172.21.39.1/24                    u/u  HAPLAN\neth0.42          192.168.39.1/24                   u/u  HEXLITELAN\n</code></pre>\n\n\n\n<hr class=\"wp-block-separator\" />\n\n\n\n<h2>VLANs &#8211; Gotta Find the Bottom!</h2>\n\n\n\n<p>Of course, if you are like me, you turn everything into a trunk to routers.</p>\n\n\n\n<p>So we are going to remove VLAN as the PVID from our VyOS-3040 facing port, and just tag it:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&#091;admin@MikroTik] &gt; export           \n# jun/29/2021 10:52:50 by RouterOS 6.48.3\n# software id = IMPN-EEMU\n#\n# model = RB750Gr3\n/interface bridge\nadd admin-mac=B8:69:F4:AB:2E:7A auto-mac=no comment=defconf name=bridgeLocal vlan-filtering=yes\n/interface vlan\nadd interface=bridgeLocal name=VLAN9_SVI vlan-id=9\n/interface bridge port\nadd bridge=bridgeLocal comment=defconf interface=ether1\n<strong>add bridge=bridgeLocal comment=defconf interface=ether2</strong>\nadd bridge=bridgeLocal comment=defconf interface=ether3 pvid=42\nadd bridge=bridgeLocal comment=defconf interface=ether4 pvid=41\nadd bridge=bridgeLocal comment=defconf interface=ether5 pvid=9\n/interface bridge vlan\nadd bridge=bridgeLocal untagged=bridgeLocal,ether1,ether2 vlan-ids=1\n<strong>add bridge=bridgeLocal tagged=bridgeLocal,ether1,ether2 untagged=ether5 vlan-ids=9</strong>\nadd bridge=bridgeLocal tagged=ether1,ether2 untagged=ether4 vlan-ids=41\nadd bridge=bridgeLocal tagged=ether1,ether2 untagged=ether3 vlan-ids=42\n/ip dhcp-client\nadd comment=defconf disabled=no interface=VLAN9_SVI\n</code></pre>\n\n\n\n<p>and a few small changes to VyOS. We move the &#8220;WAN&#8221; dhcp to a VLAN, and change the outbound-interface for the NAT:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>vyos@vyos:~$ show configuration \ninterfaces {\n    ethernet eth0 {\n        hw-id 8c:ec:4b:6d:dc:d6\n       <strong> vif 9 {\n            address dhcp\n            description WAN\n        }</strong>\n        vif 41 {\n            address 172.21.39.1/24\n            description HAPLAN\n        }\n        vif 42 {\n            address 192.168.39.1/24\n            description HEXLITELAN\n        }\n    }\n    loopback lo {\n    }\n}\nnat {\n    source {\n        rule 10 {\n            <strong>outbound-interface eth0.9</strong>\n            source {\n                address 172.21.39.0/24\n            }\n            translation {\n                address masquerade\n            }\n        }\n        rule 11 {\n            <strong>outbound-interface eth0.9</strong>\n            source {\n                address 192.168.39.0/24\n            }\n            translation {\n                address masquerade\n            }\n        }\n    }\n}\nservice {\n    dhcp-server {\n        shared-network-name HAPDHCP {\n            subnet 172.21.39.0/24 {\n                default-router 172.21.39.1\n                dns-server 10.53.53.53\n                range 0 {\n                    start 172.21.39.100\n                    stop 172.21.39.200\n                }\n            }\n        }\n        shared-network-name HEXLITEDHCP {\n            subnet 192.168.39.0/24 {\n                default-router 192.168.39.1\n                dns-server 10.53.53.53\n                range 0 {\n                    start 192.168.39.100\n                    stop 192.168.39.200\n                }\n            }\n        }\n    }\n    ssh {\n        port 22\n    }\n}</code></pre>\n\n\n\n<p>And if we show our interfaces:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>vyos@vyos:~$ show interfaces \nCodes: S - State, L - Link, u - Up, D - Down, A - Admin Down\nInterface        IP Address                        S/L  Description\n---------        ----------                        ---  -----------\neth0             -                                 u/u  \neth0.9           10.9.1.73/24                      u/u  WAN\neth0.41          172.21.39.1/24                    u/u  HAPLAN\neth0.42          192.168.39.1/24                   u/u  HEXLITELAN\nlo               127.0.0.1/8                       u/u  \n                 ::1/128                                \n</code></pre>\n\n\n\n<hr class=\"wp-block-separator\" />\n\n\n\n<h2>Conclusion</h2>\n\n\n\n<p>That&#8217;s it!  I&#8217;ve walked through going from a traditional network with 3 separate interfaces to a single interface carrying the traffic of all three networks.</p>\n\n\n\n<p>On to the next!</p>"
        }
      ],
      "post-id": "1169"
    }
  },
  {
    "blog": {
      "title": "OXcrag.net",
      "url": "https://oxcrag.net/",
      "feed": "https://oxcrag.net/feed/",
      "description": "A homelabber with view similar to mine: prefers plain Ubuntu/KVM to Proxmox,\nuses Backblaze B2, builds routers from scratch with nftables...",
      "section": "Homelab"
    },
    "entry": {
      "title": "Imported my old blog",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://oxcrag.net/feed/",
        "value": "Imported my old blog"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://oxcrag.net/2022/06/01/imported-my-old-blog/"
        }
      ],
      "link": "https://oxcrag.net/2022/06/01/imported-my-old-blog/",
      "comments": "https://oxcrag.net/2022/06/01/imported-my-old-blog/#respond",
      "authors": [
        {
          "name": "Mikael Hansson"
        }
      ],
      "author": "Mikael Hansson",
      "author_detail": {
        "name": "Mikael Hansson"
      },
      "published": "Wed, 01 Jun 2022 19:49:11 +0000",
      "published_parsed": [
        2022,
        6,
        1,
        19,
        49,
        11,
        2,
        152,
        0
      ],
      "tags": [
        {
          "term": "Site-News",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://oxcrag.net/?p=1475",
      "guidislink": false,
      "summary": "A comment on an ancient post on my old blog reminded me of its existence. I&#8217;ve now imported the material from there to my own domain and so historic posts from way-back-when can be read here. The old site will stay online for the time being, to avoid breaking possible links.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://oxcrag.net/feed/",
        "value": "A comment on an ancient post on my old blog reminded me of its existence. I&#8217;ve now imported the material from there to my own domain and so historic posts from way-back-when can be read here. The old site will stay online for the time being, to avoid breaking possible links."
      },
      "wfw_commentrss": "https://oxcrag.net/2022/06/01/imported-my-old-blog/feed/",
      "slash_comments": "0"
    }
  },
  {
    "blog": {
      "title": "Blogging to Nowhere",
      "by": "Rob Connoly",
      "url": "https://webworxshop.com/",
      "feed": "https://webworxshop.com/feed/",
      "description": "First-person view of selfhosted obsession. Ansible, GitLab CI, Docker... All\nthe good stuff.",
      "section": "Homelab"
    },
    "entry": {
      "title": "Quick Project: Splitting Docker Compose Projects",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://webworxshop.com/feed/",
        "value": "Quick Project: Splitting Docker Compose Projects"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://webworxshop.com/quick-project-splitting-docker-compose-projects/?pk_campaign=feed&pk_kwd=quick-project-splitting-docker-compose-projects"
        }
      ],
      "link": "https://webworxshop.com/quick-project-splitting-docker-compose-projects/?pk_campaign=feed&pk_kwd=quick-project-splitting-docker-compose-projects",
      "comments": "https://webworxshop.com/quick-project-splitting-docker-compose-projects/?pk_campaign=feed&pk_kwd=quick-project-splitting-docker-compose-projects#comments",
      "authors": [
        {
          "name": "Rob Connolly"
        }
      ],
      "author": "Rob Connolly",
      "author_detail": {
        "name": "Rob Connolly"
      },
      "published": "Tue, 17 Mar 2020 08:57:53 +0000",
      "published_parsed": [
        2020,
        3,
        17,
        8,
        57,
        53,
        1,
        77,
        0
      ],
      "tags": [
        {
          "term": "Projects",
          "scheme": null,
          "label": null
        },
        {
          "term": "docker",
          "scheme": null,
          "label": null
        },
        {
          "term": "quick project",
          "scheme": null,
          "label": null
        },
        {
          "term": "self-hosting",
          "scheme": null,
          "label": null
        },
        {
          "term": "traefik",
          "scheme": null,
          "label": null
        },
        {
          "term": "wordpress",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://webworxshop.com/?p=2056",
      "guidislink": false,
      "summary": "<p>Way back in the when I first started using Docker in earnest, I wrote about my web hosting stack. Recently, this has undergone an upgrade as I&#8217;m working on a new website which will be served from the same server. I took the opportunity to split the system up into multiple docker-compose projects, which makes [&#8230;]</p>\n<p>The post <a href=\"https://webworxshop.com/quick-project-splitting-docker-compose-projects/?pk_campaign=feed&#038;pk_kwd=quick-project-splitting-docker-compose-projects\" rel=\"nofollow\">Quick Project: Splitting Docker Compose Projects</a> appeared first on <a href=\"https://webworxshop.com\" rel=\"nofollow\">Blogging to Nowhere</a>.</p>\n<img alt=\"\" height=\"0\" src=\"https://analytics.webworxshop.com/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Fwebworxshop.com%2Fquick-project-splitting-docker-compose-projects%2F%3Fpk_campaign%3Dfeed%26pk_kwd%3Dquick-project-splitting-docker-compose-projects&amp;action_name=Quick+Project%3A+Splitting+Docker+Compose+Projects&amp;urlref=https%3A%2F%2Fwebworxshop.com%2Ffeed%2F\" style=\"border: 0; width: 0; height: 0;\" width=\"0\" />",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://webworxshop.com/feed/",
        "value": "<p>Way back in the when I first started using Docker in earnest, I wrote about my web hosting stack. Recently, this has undergone an upgrade as I&#8217;m working on a new website which will be served from the same server. I took the opportunity to split the system up into multiple docker-compose projects, which makes [&#8230;]</p>\n<p>The post <a href=\"https://webworxshop.com/quick-project-splitting-docker-compose-projects/?pk_campaign=feed&#038;pk_kwd=quick-project-splitting-docker-compose-projects\" rel=\"nofollow\">Quick Project: Splitting Docker Compose Projects</a> appeared first on <a href=\"https://webworxshop.com\" rel=\"nofollow\">Blogging to Nowhere</a>.</p>\n<img alt=\"\" height=\"0\" src=\"https://analytics.webworxshop.com/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Fwebworxshop.com%2Fquick-project-splitting-docker-compose-projects%2F%3Fpk_campaign%3Dfeed%26pk_kwd%3Dquick-project-splitting-docker-compose-projects&amp;action_name=Quick+Project%3A+Splitting+Docker+Compose+Projects&amp;urlref=https%3A%2F%2Fwebworxshop.com%2Ffeed%2F\" style=\"border: 0; width: 0; height: 0;\" width=\"0\" />"
      },
      "wfw_commentrss": "https://webworxshop.com/quick-project-splitting-docker-compose-projects/?pk_campaign=feed&pk_kwd=quick-project-splitting-docker-compose-projects/feed/",
      "slash_comments": "1"
    }
  },
  {
    "blog": {
      "title": "Defend the planet",
      "url": "https://defendtheplanet.net",
      "feed": "https://defendtheplanet.net/feed/",
      "description": "Tinkering with ARM single-board computers, learning to solder, designing\nrobots, building Docker swarms and repairing Volkswagen T4. Cool blog.",
      "section": "Homelab"
    },
    "entry": {
      "title": "Parsoid 0.9.0 update brings 406 Not Acceptable docserver error in VisualEditor REL_30 on Mediawiki 1.30",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://defendtheplanet.net/feed/",
        "value": "Parsoid 0.9.0 update brings 406 Not Acceptable docserver error in VisualEditor REL_30 on Mediawiki 1.30"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://defendtheplanet.net/2018/03/28/parsoid-0-9-0-update-brings-406-not-acceptable-docserver-error-in-visualeditor-rel_30-on-mediawiki-1-30/"
        }
      ],
      "link": "https://defendtheplanet.net/2018/03/28/parsoid-0-9-0-update-brings-406-not-acceptable-docserver-error-in-visualeditor-rel_30-on-mediawiki-1-30/",
      "authors": [
        {
          "name": "paul"
        }
      ],
      "author": "paul",
      "author_detail": {
        "name": "paul"
      },
      "published": "Wed, 28 Mar 2018 13:56:30 +0000",
      "published_parsed": [
        2018,
        3,
        28,
        13,
        56,
        30,
        2,
        87,
        0
      ],
      "tags": [
        {
          "term": "Uncategorized",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://defendtheplanet.net/?p=2074",
      "guidislink": false,
      "summary": "Some of my mediawiki instances broke when editing a page with VisualEditor on REL_30 today bringing HTTP 416 Errors related to Parsoid. Strangely this error only occured when editing  existing pages, simplyfied as curl below: curl \"http://NAME_OF_WIKI_HERE/api.php?action=visualeditor&#38;format=json&#38;paction=parse&#38;page=Main_Page&#38;uselang=en\" &#160; {\"error\":{\"code\":\"apierror-visualeditor-docserver-http\",\"info\":\"HTTP 406\",\"*\":\"See http://NAME_OF_WIKI_HERE/api.php for API usage. Subscribe to the mediawiki-api-announce mailing list at &#38;lt;https://lists.wikimedia.org/mailman/listinfo/mediawiki-api-announce&#38;gt; for notice of [&#8230;]",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://defendtheplanet.net/feed/",
        "value": "Some of my mediawiki instances broke when editing a page with VisualEditor on REL_30 today bringing HTTP 416 Errors related to Parsoid. Strangely this error only occured when editing  existing pages, simplyfied as curl below: curl \"http://NAME_OF_WIKI_HERE/api.php?action=visualeditor&#38;format=json&#38;paction=parse&#38;page=Main_Page&#38;uselang=en\" &#160; {\"error\":{\"code\":\"apierror-visualeditor-docserver-http\",\"info\":\"HTTP 406\",\"*\":\"See http://NAME_OF_WIKI_HERE/api.php for API usage. Subscribe to the mediawiki-api-announce mailing list at &#38;lt;https://lists.wikimedia.org/mailman/listinfo/mediawiki-api-announce&#38;gt; for notice of [&#8230;]"
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://defendtheplanet.net/feed/",
          "value": "<p>Some of my mediawiki instances broke when editing a page with VisualEditor on REL_30 today bringing HTTP 416 Errors related to Parsoid.</p>\n<p>Strangely this error only occured when editing  existing pages, simplyfied as curl below:</p>\n<pre class=\"lang:sh decode:true \">curl \"http://NAME_OF_WIKI_HERE/api.php?action=visualeditor&amp;format=json&amp;paction=parse&amp;page=Main_Page&amp;uselang=en\"</pre>\n<p>&nbsp;</p>\n<pre class=\"lang:js decode:true\">{\"error\":{\"code\":\"apierror-visualeditor-docserver-http\",\"info\":\"HTTP 406\",\"*\":\"See http://NAME_OF_WIKI_HERE/api.php for API usage. Subscribe to the mediawiki-api-announce mailing list at &amp;lt;https://lists.wikimedia.org/mailman/listinfo/mediawiki-api-announce&amp;gt; for notice of API deprecations and breaking changes.\"}}%</pre>\n<p>After a while I found that parsoid announced the behavoiur on there <a href=\"https://github.com/wikimedia/parsoid/blob/b75a2239faaa39f49ca416392d208082822a1d21/HISTORY.md\">github</a> rep:</p>\n<p style=\"padding-left: 30px;\">This release requires clients (VE, etc.) to return a 1.6.0 and greater HTML version string in the header. If not, Parsoid will return a HTTP 406. This can be fixed by updating VE (or relevant clients) to a more recent version.</p>\n<p>Unfortunately I used their .deb repository  releases.wikipedia.org which didn&#8217;t provide the 0.8.0 package for reverting the update. And since I&#8217;ve already updated  -marking it on hold in apt was no longer an option.</p>\n<p>After reading a bit through the source code the solution I found until the next mediawiki stable versions arrives can be followed by editing the</p>\n<pre class=\"lang:default decode:true \">lib/config/ParsoidConfig.js</pre>\n<p>and switch this line:</p>\n<pre class=\"lang:default decode:true\">ParsoidConfig.prototype.strictAcceptCheck = true;\n</pre>\n<p>to that</p>\n<pre class=\"lang:default decode:true \">ParsoidConfig.prototype.strictAcceptCheck = false; //true;\n</pre>\n<p>It&#8217;s not pretty, but for now it solved my issues.</p>"
        }
      ]
    }
  },
  {
    "blog": {
      "title": "JankScale Datasystems",
      "url": "https://blog.jankscale.com/",
      "feed": "https://blog.jankscale.com/rss/",
      "description": "Personal datacenter in a metal container in a backyard. There will probably\nbe some interesting posts on IaC (implied by author's reddit flair)",
      "section": "Homelab"
    },
    "entry": {
      "title": "Coming soon",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blog.jankscale.com/rss/",
        "value": "Coming soon"
      },
      "summary": "<p>This is a brand new site that&apos;s just getting started. Things will be up and running here shortly, but you can <a href=\"https://blog.jankscale.com/rss/#/portal/\" rel=\"noopener noreferrer\">subscribe</a> in the meantime if you&apos;d like to stay up to date and receive emails when new content is published!</p>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blog.jankscale.com/rss/",
        "value": "<p>This is a brand new site that&apos;s just getting started. Things will be up and running here shortly, but you can <a href=\"https://blog.jankscale.com/rss/#/portal/\" rel=\"noopener noreferrer\">subscribe</a> in the meantime if you&apos;d like to stay up to date and receive emails when new content is published!</p>"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blog.jankscale.com/coming-soon/"
        }
      ],
      "link": "https://blog.jankscale.com/coming-soon/",
      "id": "628807a0591a200001a345f2",
      "guidislink": false,
      "tags": [
        {
          "term": "News",
          "scheme": null,
          "label": null
        }
      ],
      "authors": [
        {
          "name": "Ghost"
        }
      ],
      "author": "Ghost",
      "author_detail": {
        "name": "Ghost"
      },
      "published": "Fri, 20 May 2022 21:26:56 GMT",
      "published_parsed": [
        2022,
        5,
        20,
        21,
        26,
        56,
        4,
        140,
        0
      ],
      "media_content": [
        {
          "url": "https://static.ghost.org/v4.0.0/images/feature-image.jpg",
          "medium": "image"
        }
      ],
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blog.jankscale.com/rss/",
          "value": "<img alt=\"Coming soon\" src=\"https://static.ghost.org/v4.0.0/images/feature-image.jpg\" /><p>This is a brand new site that&apos;s just getting started. Things will be up and running here shortly, but you can <a href=\"https://blog.jankscale.com/rss/#/portal/\" rel=\"noopener noreferrer\">subscribe</a> in the meantime if you&apos;d like to stay up to date and receive emails when new content is published!</p>"
        }
      ]
    }
  },
  {
    "blog": {
      "title": "Just another Linux geek",
      "url": "https://blog.christophersmart.com",
      "feed": "https://blog.christophersmart.com/feed/",
      "description": "Maintaining automatable homelab with Ansible, libvirt/KVM and Fedora. Some\nOpenWRT sprinkled here and there.",
      "section": "Homelab"
    },
    "entry": {
      "title": "Using a dynamic libvirt inventory with Ansible",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blog.christophersmart.com/feed/",
        "value": "Using a dynamic libvirt inventory with Ansible"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blog.christophersmart.com/2022/04/03/using-a-dynamic-libvirt-inventory-with-ansible/"
        }
      ],
      "link": "https://blog.christophersmart.com/2022/04/03/using-a-dynamic-libvirt-inventory-with-ansible/",
      "comments": "https://blog.christophersmart.com/2022/04/03/using-a-dynamic-libvirt-inventory-with-ansible/#comments",
      "authors": [
        {
          "name": "Chris"
        }
      ],
      "author": "Chris",
      "author_detail": {
        "name": "Chris"
      },
      "published": "Sun, 03 Apr 2022 11:35:44 +0000",
      "published_parsed": [
        2022,
        4,
        3,
        11,
        35,
        44,
        6,
        93,
        0
      ],
      "tags": [
        {
          "term": "Ansible",
          "scheme": null,
          "label": null
        },
        {
          "term": "Fedora",
          "scheme": null,
          "label": null
        },
        {
          "term": "FOSS",
          "scheme": null,
          "label": null
        },
        {
          "term": "ansible",
          "scheme": null,
          "label": null
        },
        {
          "term": "kvm",
          "scheme": null,
          "label": null
        },
        {
          "term": "libvirt",
          "scheme": null,
          "label": null
        },
        {
          "term": "qemu",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blog.christophersmart.com/?p=6748",
      "guidislink": false,
      "summary": "The Ansible community libvirt collection provides a method to interact with QEMU and LXC (if that interests you, please come and join us!). Along with support for libvirt tasks such [&#8230;]",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blog.christophersmart.com/feed/",
        "value": "The Ansible community libvirt collection provides a method to interact with QEMU and LXC (if that interests you, please come and join us!). Along with support for libvirt tasks such [&#8230;]"
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blog.christophersmart.com/feed/",
          "value": "<p>The Ansible <a href=\"https://docs.ansible.com/ansible/latest/collections/community/libvirt/index.html\">community libvirt collection</a> provides a method to interact with QEMU and LXC (if that interests you, please <a href=\"https://github.com/ansible-collections/community.libvirt\">come and join us</a>!). Along with support for libvirt tasks such as managing <a href=\"https://docs.ansible.com/ansible/latest/collections/community/libvirt/virt_module.html#ansible-collections-community-libvirt-virt-module\">guests</a>, <a href=\"https://docs.ansible.com/ansible/latest/collections/community/libvirt/virt_net_module.html#ansible-collections-community-libvirt-virt-net-module\">networks</a> and <a href=\"https://docs.ansible.com/ansible/latest/collections/community/libvirt/virt_pool_module.html#ansible-collections-community-libvirt-virt-pool-module\">storage</a>, it also <a href=\"https://docs.ansible.com/ansible/latest/collections/community/libvirt/libvirt_inventory.html\">provides a dynamic inventory</a>. This does not use SSH, but rather interacts directly with the VM over a virtual serial link using <code>qemu-guest-agent</code>, with commands executed as <code>root</code> inside the guest.</p>\n\n\n\n<p>The dynamic inventory has a couple of requirements. It does not (yet) support SELinux in enforcing mode inside the guest; it requires the <code>qemu-guest-agent</code> service to be running inside the guest; the host must be able to query <code>qemu-guest-agent</code> successfully; and <code>qemu-guest-agent</code> needs to support the following capabilities:</p>\n\n\n\n<ul><li>guest-exec</li><li>guest-file-close</li><li>guest-file-open</li><li>guest-file-read</li><li>guest-file-write</li></ul>\n\n\n\n<p>A number of distros will blacklist these in the guest&#8217;s qemu guest agent configuration, so this might need to be removed and the service restarted. In CentOS, this is configured with the <code>BLACKLIST_RPC</code> option in the <code>/etc/sysconfig/qemu-ga</code> file, so you would need to modify that and restart the <code>qemu-guest-agent</code> service.</p>\n\n\n\n<h4>Install the collection</h4>\n\n\n\n<p>To get started, we first need to install the collection.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">ansible-galaxy collection install community.libvirt</code></pre>\n\n\n\n<h4>Create an inventory file</h4>\n\n\n\n<p>Next, to use it as a dynamic inventory and talk to a working <code>libvirtd</code>, we need to create an inventory file which provides the connection details for our hypervisor. In this example, we&#8217;re creating a file called <code>kvm.yml</code> which provides the <code>uri</code> to talk to the local daemon supervising QEMU domains.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-yaml\" lang=\"yaml\">---\nplugin: community.libvirt.libvirt\nuri: 'qemu:///system'</code></pre>\n\n\n\n<p>Now that we have our inventory file, we can test it!</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">ansible-inventory --inventory kvm.yml --list</code></pre>\n\n\n\n<span id=\"more-6748\"></span>\n\n\n\n<p>This should return JSON formatted data, which looks like this on a hypervisor with no guests.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-json\" lang=\"json\">{\n    \"_meta\": {\n        \"hostvars\": {}\n    },\n    \"all\": {\n        \"children\": [\n            \"ungrouped\"\n        ]\n    }\n}\n</code></pre>\n\n\n\n<h5>Inventory with a remote host</h5>\n\n\n\n<p>The cool thing is that it supports standard URI connection strings, so we can also talk to remote libvirt hosts over SSH with an inventory like this.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-yaml\" lang=\"yaml\">---\nplugin: community.libvirt.libvirt\nuri: 'qemu+ssh://user@server/system'</code></pre>\n\n\n\n<h4>Spin up VMs</h4>\n\n\n\n<p>OK! Spin up some test virtual machines and try listing the inventory again.</p>\n\n\n\n<p>If you need a hand creating some VMs, then we can do it with my <a href=\"https://github.com/csmart/virt-infra-ansible\">Ansible virtual infrastructure playbook</a>, which pulls in <a href=\"https://github.com/csmart/ansible-role-virt-infra\">my role</a> and includes a sample inventory. Running this will also automatically install and start everything on <code>localhost</code> that we need for <code>libvirtd</code>.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">git clone --recursive https://github.com/csmart/virt-infra-ansible.git\ncd virt-infra-ansible</code></pre>\n\n\n\n<p>Let&#8217;s grab the CentOS Stream 8 images and put them in place so that we can spin up the VMs.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">curl -O https://cloud.centos.org/centos/8-stream/x86_64/images/CentOS-Stream-GenericCloud-8-20210603.0.x86_64.qcow2\nsudo mkdir -p /var/lib/libvirt/images\nsudo mv -iv CentOS-Stream-GenericCloud-8-20210603.0.x86_64.qcow2 /var/lib/libvirt/images/</code></pre>\n\n\n\n<p>Next, let&#8217;s create some extra args so that the Ansible role can put SELinux into permissive mode and configure <code>qemu-guest-agent</code> capabilities for us automatically.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">cat &gt; /tmp/ansible-extra-args.json &lt;&lt; \\EOF\n{\n  \"virt_infra_disk_cmd\": [\n    \"sed -i s/^BLACKLIST_RPC=/\\\\#BLACKLIST_RPC=/ /etc/sysconfig/qemu-ga\",\n    \"sed -i s/^SELINUX=.*/SELINUX=permissive/ /etc/selinux/config\"\n  ]\n}\nEOF</code></pre>\n\n\n\n<p>OK! Now we can spin up two VMs, <code>simple-centos-8-1</code> and <code>example-centos-8</code> from the included sample inventory and test if we can see them using the dynamic inventory.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">./run.sh --limit kvmhost,simple-centos-8-1,example-centos-8 --extra-vars \"@/tmp/ansible-extra-args.json\"</code></pre>\n\n\n\n<p>This should successfully spin up those two machines, which we can remove cleanly in a later step. If you need to SSH into them for some reason, they should be configured with a local account that matches Linux username, with a password of <code>password</code> and be accessible with any of the SSH keys from your home directory.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">ssh example-centos-8 uptime</code></pre>\n\n\n\n<h4>Test the dynamic inventory</h4>\n\n\n\n<p>Let&#8217;s try the dynamic inventory again and see if we can find those new VMs.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">ansible-inventory --inventory kvm.yml --list</code></pre>\n\n\n\n<p>This time the returned JSON includes the VMs. Note that groups are automatically created for each host.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-json\" lang=\"json\">{\n    \"1c85f707-70bd-4449-9e74-0364329b2cae\": {\n        \"hosts\": [\n            \"simple-centos-8-1\"\n        ]\n    },\n    \"73d59360-33f9-44e6-8c71-0ac2f6530c43\": {\n        \"hosts\": [\n            \"example-centos-8\"\n        ]\n    },\n    \"_meta\": {\n        \"hostvars\": {\n            \"example-centos-8\": {\n                \"ansible_connection\": \"community.libvirt.libvirt_qemu\",\n                \"ansible_libvirt_uri\": \"qemu:///system\"\n            },\n            \"simple-centos-8-1\": {\n                \"ansible_connection\": \"community.libvirt.libvirt_qemu\",\n                \"ansible_libvirt_uri\": \"qemu:///system\"\n            }\n        }\n    },\n    \"all\": {\n        \"children\": [\n            \"1c85f707-70bd-4449-9e74-0364329b2cae\",\n            \"73d59360-33f9-44e6-8c71-0ac2f6530c43\",\n            \"ungrouped\"\n        ]\n    }\n}</code></pre>\n\n\n\n<h4>Test guest agent</h4>\n\n\n\n<p>We can use the <code>virsh</code> command line tool to test that the host is able to communicate with the guest agent running in the VM, and that it supports the capabilities that we need. Let&#8217;s do that now, against one of the example VMs.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">sudo virsh qemu-agent-command example-centos-8 '{\"execute\":\"guest-info\"}' --pretty</code></pre>\n\n\n\n<p>Firstly, this needs to work and secondly, it should return a list of supported commands where you can ensure the required capabilities are enabled and working.</p>\n\n\n\n<h4>Use the dynamic inventory with Ansible</h4>\n\n\n\n<p>Now that we have a working inventory and have confirmed the guest agent connection is working, we can use Ansible to dynamically generate an inventory and connect to the guests. Again, this doesn&#8217;t use SSH, but rather the <code>gemu-guest-agent</code> interface.</p>\n\n\n\n<p>Let&#8217;s test this using the standard Ansible <code>ping</code> module.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">ansible --inventory kvm.yml all -m ping</code></pre>\n\n\n\n<p>We should see a successful response!</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"\">simple-centos-8-1 | SUCCESS =&gt; {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/libexec/platform-python\"\n    },\n    \"changed\": false,\n    \"ping\": \"pong\"\n}\nexample-centos-8 | SUCCESS =&gt; {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/libexec/platform-python\"\n    },\n    \"changed\": false,\n    \"ping\": \"pong\"\n}</code></pre>\n\n\n\n<p>And of course we can run real playbooks. Here&#8217;s an example playbook called <code>site.yml</code> to install critical packages <img alt=\"😉\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/14.0.0/72x72/1f609.png\" style=\"height: 1em;\" /></p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-yaml\" lang=\"yaml\">---\n- hosts: all\n  tasks:\n    - name: Install packages\n      package:\n        name:\n          - git\n          - rsync\n          - tmux\n          - vim\n        state: present\n      become: true\n      register: result_package_install\n      retries: 10\n      delay: 5\n      until: result_package_install is succeeded</code></pre>\n\n\n\n<p>Let&#8217;s run it!</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">ansible-playbook --inventory kvm.yml site.yml</code></pre>\n\n\n\n<p>And we should see that it happily executes the playbook.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"\">PLAY [all] ******************************************************************************************\n\nTASK [Gathering Facts] ******************************************************************************\nok: [simple-centos-8-1]\nok: [example-centos-8]\n\nTASK [Install packages] *****************************************************************************\nchanged: [example-centos-8]\nchanged: [simple-centos-8-1]\n\nPLAY RECAP ******************************************************************************************\nexample-centos-8     : ok=2  changed=1  unreachable=0  failed=0    skipped=0  rescued=0  ignored=0   \nsimple-centos-8-1    : ok=2  changed=1  unreachable=0  failed=0    skipped=0  rescued=0  ignored=0   </code></pre>\n\n\n\n<h5>Limiting the hosts with dynamic inventory</h5>\n\n\n\n<p>Now that you have a working dynamic inventory, you can use the standard Ansible <code>limit</code> option to restrict machines for your playbooks. This way you can have the flexibility of the dynamic inventory, but restrict which guests you execute Ansible against.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">ansible-playbook --inventory kvm.yml --limit example-centos-8 site.yml</code></pre>\n\n\n\n<h4>Remove test VMs</h4>\n\n\n\n<p>Finally, we can cleanly remove those test VMs using the same Ansible code, by setting their state to <code>undefined</code>.</p>\n\n\n\n<pre class=\"wp-block-code\"><code class=\"language-bash line-numbers\" lang=\"bash\">./run.sh --limit kvmhost,simple-centos-8-1,example-centos-8 -e virt_infra_state=undefined</code></pre>\n\n\n\n<p>And there you have it. Using the dynamic inventory with the libvirt plugin can be quite handy.</p>"
        }
      ],
      "wfw_commentrss": "https://blog.christophersmart.com/2022/04/03/using-a-dynamic-libvirt-inventory-with-ansible/feed/",
      "slash_comments": "1"
    }
  },
  {
    "blog": {
      "title": "YetiOps",
      "url": "https://yetiops.net/posts/",
      "feed": "https://yetiops.net/posts/index.xml",
      "description": "Homelab, Ansible, KVM, Terraform, Pulumi",
      "section": "Homelab"
    },
    "entry": {
      "title": "Home and Personal Infrastructure Overhaul: Part 7 - Using Drone with Terraform",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://yetiops.net/posts/index.xml",
        "value": "Home and Personal Infrastructure Overhaul: Part 7 - Using Drone with Terraform"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://yetiops.net/posts/home-infra-overhaul-part7-drone-terraform/"
        }
      ],
      "link": "https://yetiops.net/posts/home-infra-overhaul-part7-drone-terraform/",
      "published": "Sun, 05 Jun 2022 08:27:30 +0100",
      "published_parsed": [
        2022,
        6,
        5,
        7,
        27,
        30,
        6,
        156,
        0
      ],
      "id": "https://yetiops.net/posts/home-infra-overhaul-part7-drone-terraform/",
      "guidislink": false,
      "summary": "This post is the next in the series on how I overhauled my personal infrastructure to make it easier to manage, make changes and integrate new applications.\nPrevious posts in the series are: -\n Introduction Ansible Improvements SaltStack Improvements Introduction to Drone CI Using Drone with Ansible Using Drone with Salt  This post will cover using Drone to manage and deploy resources with Terraform.\nBackground When I first started using Drone, I wasn&rsquo;t using it with Terraform.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://yetiops.net/posts/index.xml",
        "value": "This post is the next in the series on how I overhauled my personal infrastructure to make it easier to manage, make changes and integrate new applications.\nPrevious posts in the series are: -\n Introduction Ansible Improvements SaltStack Improvements Introduction to Drone CI Using Drone with Ansible Using Drone with Salt  This post will cover using Drone to manage and deploy resources with Terraform.\nBackground When I first started using Drone, I wasn&rsquo;t using it with Terraform."
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://yetiops.net/posts/index.xml",
          "value": "<p>This post is the next in the series on how I overhauled my personal infrastructure to make it easier to manage, make changes and integrate new applications.</p>\n<p>Previous posts in the series are: -</p>\n<ul>\n<li><a href=\"https://yetiops.net/posts/home-infra-overhaul-part1/\">Introduction</a></li>\n<li><a href=\"https://yetiops.net/posts/home-infra-overhaul-part2-ansible-improvements/\">Ansible Improvements</a></li>\n<li><a href=\"https://yetiops.net/posts/home-infra-overhaul-part3-salt-improvements/\">SaltStack Improvements</a></li>\n<li><a href=\"https://yetiops.net/posts/home-infra-overhaul-part4-drone-getting-started/\">Introduction to Drone CI</a></li>\n<li><a href=\"https://yetiops.net/posts/home-infra-overhaul-part5-drone-ansible/\">Using Drone with Ansible</a></li>\n<li><a href=\"https://yetiops.net/posts/home-infra-overhaul-part6-drone-salt/\">Using Drone with Salt</a></li>\n</ul>\n<p>This post will cover using Drone to manage and deploy resources with Terraform.</p>\n<h2 id=\"background\">Background</h2>\n<p>When I first started using Drone, I wasn&rsquo;t using it with Terraform. In fact very little of my infrastructure was managed by Terraform. Recently though, I decided to start moving most external services to it. In keeping with my theme of trying to automate my infrastructure and avoid manual changes, it made sense to finally start using Terraform for my personal usage of external services.</p>\n<p>Ansible and Salt still control what runs on my machines (including VPSs/instances on cloud providers), but managing external services makes a lot of sense with Terraform. While Ansible and Salt are good at making changes, they don&rsquo;t manage &ldquo;desired state&rdquo; very well, in the sense that Ansible can create a VPS on Hetzner, but it does not know that one may already exist.</p>\n<p>With Terraform, it knows what resources it manages (using State management), and whether they should already exist or not. Terraform may still be incorrect as to the state of a resource, but usually only if the resource changed since the last time Terraform ran. Something like Ansible will just try to make the same changes it did last time, which could lead to duplicate resources, or the Playbook failing because it can&rsquo;t create a resource (because it already exists and can&rsquo;t be created again).</p>\n<p>The following covers what I use: -</p>\n<ul>\n<li>Cloudflare for external DNS\n<ul>\n<li>This includes externally accessibly domains</li>\n<li>It also includes &ldquo;internal&rdquo; domains I use that I want valid Let&rsquo;s Encrypt certificates for</li>\n</ul>\n</li>\n<li>Digital Ocean and Hetzner for VPSs\n<ul>\n<li>My blog and other external services (RSS, Read-It-Later, Black Box Exporter for monitoring) are hosted on these</li>\n</ul>\n</li>\n<li>Google Cloud Platform and Oracle Cloud Infrastructure for the always-free virtual machines</li>\n<li>Lab/Proxmox for testing technologies</li>\n</ul>\n<p>For most of these, the steps are the same, with some minor differences in variable/secrets for each provider). In some cases, extra steps are required. I&rsquo;ll first show the most basic pipeline (the one used for Cloudflare DNS) and then show some of the extra steps in others.</p>\n<h2 id=\"full-drone-pipeline---cloudflare\">Full Drone Pipeline - Cloudflare</h2>\n<div class=\"highlight\"><pre><code class=\"language-yaml\"><span style=\"color: #66d9ef;\">kind</span>: pipeline\n<span style=\"color: #66d9ef;\">name</span>: default\n<span style=\"color: #66d9ef;\">type</span>: docker\n\n<span style=\"color: #66d9ef;\">trigger</span>:\n  <span style=\"color: #66d9ef;\">branch</span>:\n    - main\n\n<span style=\"color: #66d9ef;\">steps</span>:\n  - <span style=\"color: #66d9ef;\">name</span>: Terraform FMT PR\n    <span style=\"color: #66d9ef;\">image</span>: jmccann/drone-terraform:latest\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">actions</span>:\n        - fmt\n      <span style=\"color: #66d9ef;\">fmt_options</span>:\n        <span style=\"color: #66d9ef;\">write</span>: <span style=\"color: #66d9ef;\">false</span>\n        <span style=\"color: #66d9ef;\">diff</span>: <span style=\"color: #66d9ef;\">true</span>\n        <span style=\"color: #66d9ef;\">check</span>: <span style=\"color: #66d9ef;\">true</span>\n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">event</span>:\n      - pull_request\n\n  - <span style=\"color: #66d9ef;\">name</span>: Terraform Plan\n    <span style=\"color: #66d9ef;\">image</span>: jmccann/drone-terraform:latest\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">actions</span>:\n        - validate\n        - plan\n    <span style=\"color: #66d9ef;\">environment</span>:\n      <span style=\"color: #66d9ef;\">DIGITALOCEAN_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: digitalocean_token \n      <span style=\"color: #66d9ef;\">HCLOUD_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: hcloud_token\n      <span style=\"color: #66d9ef;\">CLOUDFLARE_API_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: cloudflare_api_token\n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">event</span>:\n      - pull_request\n\n  - <span style=\"color: #66d9ef;\">name</span>: slack-pr\n    <span style=\"color: #66d9ef;\">image</span>: plugins/slack\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">webhook</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: drone_builds_slack_webhook \n      <span style=\"color: #66d9ef;\">channel</span>: builds\n      <span style=\"color: #66d9ef;\">template</span>: <span style=\"color: #e6db74;\">&gt;\n</span><span style=\"color: #e6db74;\">        {{#success build.status}}</span>\n          {{repo.name}} PR build passed. \n          Merge in to apply.\n          <span style=\"color: #66d9ef;\">PR</span>: https://git.noisepalace.co.uk/YetiOps/{{repo.name}}/pulls/{{build.pull}}\n          <span style=\"color: #66d9ef;\">Build</span>: https://drone.noisepalace.co.uk/YetiOps/{{repo.name}}/{{build.number}}\n        {{else}}\n          {{repo.name}} PR build failed. \n          Please investigate. \n          <span style=\"color: #66d9ef;\">PR</span>: https://git.noisepalace.co.uk/YetiOps/{{repo.name}}/pulls/{{build.pull}}\n          <span style=\"color: #66d9ef;\">Build</span>: https://drone.noisepalace.co.uk/YetiOps/{{repo.name}}/{{build.number}}\n        {{/success}}            \n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">status</span>:\n      - failure\n      - success\n      <span style=\"color: #66d9ef;\">event</span>:\n        - pull_request\n\n  - <span style=\"color: #66d9ef;\">name</span>: slack-push-start\n    <span style=\"color: #66d9ef;\">image</span>: plugins/slack\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">webhook</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: drone_builds_slack_webhook \n      <span style=\"color: #66d9ef;\">channel</span>: builds\n      <span style=\"color: #66d9ef;\">template</span>: <span style=\"color: #e6db74;\">&gt;\n</span><span style=\"color: #e6db74;\">        {{repo.name}} build is starting.</span>\n        <span style=\"color: #66d9ef;\">Build</span>: https://drone.noisepalace.co.uk/YetiOps/{{repo.name}}/{{build.number}}      \n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">branch</span>:\n      - main\n      <span style=\"color: #66d9ef;\">event</span>:\n      - push\n      - tag\n  \n  - <span style=\"color: #66d9ef;\">name</span>: Terraform FMT\n    <span style=\"color: #66d9ef;\">image</span>: jmccann/drone-terraform:latest\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">actions</span>:\n        - fmt\n      <span style=\"color: #66d9ef;\">fmt_options</span>:\n        <span style=\"color: #66d9ef;\">write</span>: <span style=\"color: #66d9ef;\">false</span>\n        <span style=\"color: #66d9ef;\">diff</span>: <span style=\"color: #66d9ef;\">true</span>\n        <span style=\"color: #66d9ef;\">check</span>: <span style=\"color: #66d9ef;\">true</span>\n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">branch</span>:\n      - main\n      <span style=\"color: #66d9ef;\">event</span>:\n      - push\n      - tag\n\n\n  - <span style=\"color: #66d9ef;\">name</span>: Terraform Apply\n    <span style=\"color: #66d9ef;\">image</span>: jmccann/drone-terraform:latest\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">actions</span>:\n        - validate\n        - plan\n        - apply\n    <span style=\"color: #66d9ef;\">environment</span>:\n      <span style=\"color: #66d9ef;\">DIGITALOCEAN_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: digitalocean_token \n      <span style=\"color: #66d9ef;\">HCLOUD_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: hcloud_token\n      <span style=\"color: #66d9ef;\">CLOUDFLARE_API_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: cloudflare_api_token\n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">branch</span>:\n      - main\n      <span style=\"color: #66d9ef;\">event</span>:\n      - push\n      - tag\n\n  - <span style=\"color: #66d9ef;\">name</span>: slack-push\n    <span style=\"color: #66d9ef;\">image</span>: plugins/slack\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">webhook</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: drone_builds_slack_webhook \n      <span style=\"color: #66d9ef;\">channel</span>: builds\n      <span style=\"color: #66d9ef;\">template</span>: <span style=\"color: #e6db74;\">&gt;\n</span><span style=\"color: #e6db74;\">        {{#success build.status}}</span>\n          {{repo.name}} build passed.\n          <span style=\"color: #66d9ef;\">Build</span>: https://drone.noisepalace.co.uk/YetiOps/{{repo.name}}/{{build.number}}\n        {{else}}\n          {{repo.name}} build {{build.number}} failed. Please investigate. \n          <span style=\"color: #66d9ef;\">Build</span>: https://drone.noisepalace.co.uk/YetiOps/{{repo.name}}/{{build.number}}\n        {{/success}}            \n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">status</span>:\n      - failure\n      - success\n      <span style=\"color: #66d9ef;\">branch</span>:\n      - main\n      <span style=\"color: #66d9ef;\">event</span>:\n      - push\n      - tag\n</code></pre></div><p>This pipeline is very similar to the one used for <a href=\"https://yetiops.net/posts/home-infra-overhaul-part5-drone-ansible/#full-drone-pipeline\">Ansible</a>. This uses the same Slack notification steps, the same kind of triggers/conditionals for running steps, and runs as a single Docker-based pipeline (rather than the multiple pipelines required for <a href=\"https://yetiops.net/posts/home-infra-overhaul-part6-drone-salt/#full-drone-pipeline\">Salt</a>).</p>\n<p>The bulk of the Terraform-specific steps in the pipelines use the <a href=\"https://plugins.drone.io/plugins/terraform\">Terraform Drone plugin</a>. It is possible to use the official Hashicorp Terraform Docker image, but the Drone plugin is a little more convenient. If you use the official Hashicorp Terraform Docker image, you need to define each command you want to run, whereas the plugin reduces most commands to fields.</p>\n<h3 id=\"steps---terraform-fmt\">Steps - Terraform FMT</h3>\n<div class=\"highlight\"><pre><code class=\"language-yaml\">- <span style=\"color: #66d9ef;\">name</span>: Terraform FMT PR\n  <span style=\"color: #66d9ef;\">image</span>: jmccann/drone-terraform:latest\n  <span style=\"color: #66d9ef;\">settings</span>:\n    <span style=\"color: #66d9ef;\">actions</span>:\n      - fmt\n    <span style=\"color: #66d9ef;\">fmt_options</span>:\n      <span style=\"color: #66d9ef;\">write</span>: <span style=\"color: #66d9ef;\">false</span>\n      <span style=\"color: #66d9ef;\">diff</span>: <span style=\"color: #66d9ef;\">true</span>\n      <span style=\"color: #66d9ef;\">check</span>: <span style=\"color: #66d9ef;\">true</span>\n  <span style=\"color: #66d9ef;\">when</span>:\n    <span style=\"color: #66d9ef;\">event</span>:\n    - pull_request\n</code></pre></div><p>This step is the same as running the <code>terraform fmt</code> command with the flags <code>-diff</code> and <code>-check</code>. While this isn&rsquo;t a necessary step, it does apply some consistent formatting rules to Terraform files.</p>\n<p>In the <code>diff</code> and <code>check</code> mode, it doesn&rsquo;t make any changes, but will fail if <code>terraform fmt</code> mentions any required changes (as it will exit with a <strong>non-zero</strong> exit code).</p>\n<p><img alt=\"Terraform Drone FMT step\" src=\"https://yetiops.net/img/homeinfra/drone-terraform-fmt.png\" /></p>\n<h3 id=\"steps---terraform-plan\">Steps - Terraform Plan</h3>\n<div class=\"highlight\"><pre><code class=\"language-yaml\">  - <span style=\"color: #66d9ef;\">name</span>: Terraform Plan\n    <span style=\"color: #66d9ef;\">image</span>: jmccann/drone-terraform:latest\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">actions</span>:\n        - validate\n        - plan\n    <span style=\"color: #66d9ef;\">environment</span>:\n      <span style=\"color: #66d9ef;\">DIGITALOCEAN_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: digitalocean_token \n      <span style=\"color: #66d9ef;\">HCLOUD_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: hcloud_token\n      <span style=\"color: #66d9ef;\">CLOUDFLARE_API_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: cloudflare_api_token\n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">event</span>:\n      - pull_request\n</code></pre></div><p>This step runs <code>terraform validate</code> and <code>terraform plan</code>. Validate ensures that the Terraform configuration is correct (i.e. brackets in the correct place, variables defined correctly etc), and the Plan stage shows the changes Terraform wants to make.</p>\n<p>In this Drone expose a set of environment variables, namely my Digital Ocean API token, Hetzner HCloud API token and the Cloudflare API token. It uses the Digital Ocean and Hetzner tokens to create DNS records for the public IPs of my VPSs within Hetzner and Digital Ocean, and the Cloudflare API token is used to read/write updates to the Cloudflare API. An example of the relevant Terraform code is shown below: -</p>\n<p><strong>data.tf</strong></p>\n<div class=\"highlight\"><pre><code class=\"language-hcl\"><span style=\"color: #66d9ef;\">data</span> <span style=\"color: #e6db74;\">\"hcloud_server\" \"hcloud-vps-a\"</span> {\n  name <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps-shme-hcloud-a\"</span>\n}\n\n<span style=\"color: #66d9ef;\">data</span> <span style=\"color: #e6db74;\">\"hcloud_server\" \"hcloud-vps-b\"</span> {\n  name <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps-shme-hcloud-b\"</span>\n}\n\n<span style=\"color: #66d9ef;\">data</span> <span style=\"color: #e6db74;\">\"digitalocean_droplet\" \"vps-shme\"</span> {\n  name <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps-shme\"</span>\n}\n</code></pre></div><p><strong>main.tf</strong></p>\n<div class=\"highlight\"><pre><code class=\"language-hcl\"><span style=\"color: #75715e;\"># VPS Records - IPv4\n</span><span style=\"color: #75715e;\"></span>\n<span style=\"color: #66d9ef;\">resource</span> <span style=\"color: #e6db74;\">\"cloudflare_record\" \"vps-a\"</span> {\n  zone_id <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">local</span>.<span style=\"color: #66d9ef;\">this_zone_id</span>\n  name    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps-a\"</span>\n  type    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"A\"</span>\n  proxied <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"false\"</span>\n  value   <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">data</span>.<span style=\"color: #66d9ef;\">hcloud_server</span>.<span style=\"color: #66d9ef;\">hcloud</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">vps</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">a</span>.<span style=\"color: #66d9ef;\">ipv4_address</span>\n}\n\n<span style=\"color: #66d9ef;\">resource</span> <span style=\"color: #e6db74;\">\"cloudflare_record\" \"vps-b\"</span> {\n  zone_id <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">local</span>.<span style=\"color: #66d9ef;\">this_zone_id</span>\n  name    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps-b\"</span>\n  type    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"A\"</span>\n  proxied <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"false\"</span>\n  value   <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">data</span>.<span style=\"color: #66d9ef;\">hcloud_server</span>.<span style=\"color: #66d9ef;\">hcloud</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">vps</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">b</span>.<span style=\"color: #66d9ef;\">ipv4_address</span>\n}\n\n<span style=\"color: #66d9ef;\">resource</span> <span style=\"color: #e6db74;\">\"cloudflare_record\" \"vps-shme\"</span> {\n  zone_id <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">local</span>.<span style=\"color: #66d9ef;\">this_zone_id</span>\n  name    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps\"</span>\n  type    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"A\"</span>\n  proxied <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"false\"</span>\n  value   <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">data</span>.<span style=\"color: #66d9ef;\">digitalocean_droplet</span>.<span style=\"color: #66d9ef;\">vps</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">shme</span>.<span style=\"color: #66d9ef;\">ipv4_address</span>\n}<span style=\"color: #75715e;\">\n</span><span style=\"color: #75715e;\">\n</span><span style=\"color: #75715e;\"># VPS Records - IPv6\n</span><span style=\"color: #75715e;\"></span>\n<span style=\"color: #66d9ef;\">resource</span> <span style=\"color: #e6db74;\">\"cloudflare_record\" \"vps-a-v6\"</span> {\n  zone_id <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">local</span>.<span style=\"color: #66d9ef;\">this_zone_id</span>\n  name    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps-a\"</span>\n  type    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"AAAA\"</span>\n  proxied <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"false\"</span>\n  value   <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">data</span>.<span style=\"color: #66d9ef;\">hcloud_server</span>.<span style=\"color: #66d9ef;\">hcloud</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">vps</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">a</span>.<span style=\"color: #66d9ef;\">ipv6_address</span>\n}\n\n<span style=\"color: #66d9ef;\">resource</span> <span style=\"color: #e6db74;\">\"cloudflare_record\" \"vps-b-v6\"</span> {\n  zone_id <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">local</span>.<span style=\"color: #66d9ef;\">this_zone_id</span>\n  name    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps-b\"</span>\n  type    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"AAAA\"</span>\n  proxied <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"false\"</span>\n  value   <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">data</span>.<span style=\"color: #66d9ef;\">hcloud_server</span>.<span style=\"color: #66d9ef;\">hcloud</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">vps</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">b</span>.<span style=\"color: #66d9ef;\">ipv6_address</span>\n}\n\n<span style=\"color: #66d9ef;\">resource</span> <span style=\"color: #e6db74;\">\"cloudflare_record\" \"vps-shme-v6\"</span> {\n  zone_id <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">local</span>.<span style=\"color: #66d9ef;\">this_zone_id</span>\n  name    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"vps\"</span>\n  type    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"AAAA\"</span>\n  proxied <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"false\"</span>\n  value   <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">data</span>.<span style=\"color: #66d9ef;\">digitalocean_droplet</span>.<span style=\"color: #66d9ef;\">vps</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">shme</span>.<span style=\"color: #66d9ef;\">ipv6_address</span>\n}\n</code></pre></div><p>As you can see, this uses data sources to get information from Digital Ocean and Hetzner, and then applies the IPv4/IPv6 addresses as values in <code>cloudflare_record</code> resources.</p>\n<p>I also create DNS records for instances within Google Cloud Platform and Oracle Cloud Infrastructure, but with these I use <a href=\"https://www.terraform.io/language/state/remote\">Terraform Remote State</a>. The reason for this is that both of these require extra configuration and files (GPG keys for OCI, a JSON document for GCP) that add extra steps and complication to the pipeline. While this does mean that I am reliant on the Terraform Remote State being up to date (rather than a direct data source like for Digital Ocean or Hetzner), I accept this trade off to avoid the additional complexity.</p>\n<p>The relevant Terraform for the GCP and OCI records are shown below: -</p>\n<p><strong>data.tf</strong></p>\n<div class=\"highlight\"><pre><code class=\"language-hcl\"><span style=\"color: #66d9ef;\">data</span> <span style=\"color: #e6db74;\">\"terraform_remote_state\" \"oracle-ork\"</span> {\n  backend <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"consul\"</span>\n  config <span style=\"color: #f92672;\">=</span> {\n    address <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"consul.noisepalace.co.uk\"</span>\n    scheme  <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"https\"</span>\n    path    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"terraform/oraclecloud/oci\"</span>\n  }\n}\n\n<span style=\"color: #66d9ef;\">data</span> <span style=\"color: #e6db74;\">\"terraform_remote_state\" \"yetiops-goggle\"</span> {\n  backend <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"consul\"</span>\n  config <span style=\"color: #f92672;\">=</span> {\n    address <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"consul.noisepalace.co.uk\"</span>\n    scheme  <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"https\"</span>\n    path    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"terraform/gcp/yetiops-goggle\"</span>\n  }\n}\n</code></pre></div><p><strong>main.tf</strong></p>\n<div class=\"highlight\"><pre><code class=\"language-hcl\"><span style=\"color: #66d9ef;\">resource</span> <span style=\"color: #e6db74;\">\"cloudflare_record\" \"vps-ork-01\"</span> {\n  zone_id <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">local</span>.<span style=\"color: #66d9ef;\">this_zone_id</span>\n  name    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"ork-01\"</span>\n  type    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"A\"</span>\n  proxied <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"false\"</span>\n  value   <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">data</span>.<span style=\"color: #66d9ef;\">terraform_remote_state</span>.<span style=\"color: #66d9ef;\">oracle</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">ork</span>.<span style=\"color: #66d9ef;\">outputs</span>.<span style=\"color: #66d9ef;\">instance_public_ip</span>\n}\n\n<span style=\"color: #66d9ef;\">resource</span> <span style=\"color: #e6db74;\">\"cloudflare_record\" \"vps-gog-01\"</span> {\n  zone_id <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">local</span>.<span style=\"color: #66d9ef;\">this_zone_id</span>\n  name    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"gog-01\"</span>\n  type    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"A\"</span>\n  proxied <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"false\"</span>\n  value   <span style=\"color: #f92672;\">=</span> <span style=\"color: #66d9ef;\">data</span>.<span style=\"color: #66d9ef;\">terraform_remote_state</span>.<span style=\"color: #66d9ef;\">yetiops</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">goggle</span>.<span style=\"color: #66d9ef;\">outputs</span>.<span style=\"color: #66d9ef;\">gog</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #ae81ff;\">01</span><span style=\"color: #960050; background-color: #1e0010;\">-</span><span style=\"color: #66d9ef;\">ipv4</span>\n}\n</code></pre></div><p>These use Consul as the source for Remote State. More details on this are in <a href=\"https://yetiops.net/posts/index.xml#remote-state-backend-with-consul\">this section</a>.</p>\n<p>The Drone step will run a plan against these resources (and all other defined resources), and show what changes need to be made (if any).</p>\n<p><img alt=\"Terraform Drone Plan\" src=\"https://yetiops.net/img/homeinfra/drone-terraform-plan.png\" /></p>\n<h3 id=\"steps---terraform-apply\">Steps - Terraform Apply</h3>\n<div class=\"highlight\"><pre><code class=\"language-yaml\">  - <span style=\"color: #66d9ef;\">name</span>: Terraform Apply\n    <span style=\"color: #66d9ef;\">image</span>: jmccann/drone-terraform:latest\n    <span style=\"color: #66d9ef;\">settings</span>:\n      <span style=\"color: #66d9ef;\">actions</span>:\n        - validate\n        - plan\n        - apply\n    <span style=\"color: #66d9ef;\">environment</span>:\n      <span style=\"color: #66d9ef;\">DIGITALOCEAN_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: digitalocean_token \n      <span style=\"color: #66d9ef;\">HCLOUD_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: hcloud_token\n      <span style=\"color: #66d9ef;\">CLOUDFLARE_API_TOKEN</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: cloudflare_api_token\n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">branch</span>:\n      - main\n      <span style=\"color: #66d9ef;\">event</span>:\n      - push\n      - tag\n</code></pre></div><p>This step is almost identical to the Plan stage. The only difference is that it uses the <code>apply</code> action as well. This runs a <code>validate</code> and a <code>plan</code> action (to ensure that the code is still valid when merged with the main branch) and then applies the changes.</p>\n<p>This is all controlled via Gitea pull requests, meaning that any PRs raised will go through all the validation and planning steps. Changes are then applied without any human interaction with the Terraform CLI itself.</p>\n<p><img alt=\"Drone Terraform Apply\" src=\"https://yetiops.net/img/homeinfra/drone-terraform-apply.png\" /></p>\n<p>For most Terraform code, these are all the steps you will need.</p>\n<h2 id=\"additional-steps\">Additional steps</h2>\n<p>As noted above, most of my Terraform code doesn&rsquo;t need anything more than the steps covered already. The secrets to expose may differ (based upon the infrastructure used), otherwise everything else is the same.</p>\n<p>However for some Terraform code, I need to make files available (e.g. SSH keys, GPG keys, configuration objects). The following step covers how to do this: -</p>\n<div class=\"highlight\"><pre><code class=\"language-yaml\"><span style=\"color: #66d9ef;\">steps</span>:\n  - <span style=\"color: #66d9ef;\">name</span>: Place SSH keys - PR\n    <span style=\"color: #66d9ef;\">image</span>: alpine\n    <span style=\"color: #66d9ef;\">environment</span>: \n      <span style=\"color: #66d9ef;\">SSH_PRIV</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: drone_ssh_priv\n      <span style=\"color: #66d9ef;\">SSH_PUB</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: drone_ssh_pub\n      <span style=\"color: #66d9ef;\">OCI_PRIVATE_KEY</span>:\n        <span style=\"color: #66d9ef;\">from_secret</span>: oci_private_key\n    <span style=\"color: #66d9ef;\">volumes</span>:\n      - <span style=\"color: #66d9ef;\">name</span>: cache\n        <span style=\"color: #66d9ef;\">path</span>: /ssh\n    <span style=\"color: #66d9ef;\">commands</span>:\n      - echo -e <span style=\"color: #e6db74;\">\"$SSH_PRIV\"</span> | tee /ssh/id_rsa\n      - echo -e <span style=\"color: #e6db74;\">\"$SSH_PUB\"</span> | tee /ssh/id_rsa.pub\n      - echo -e <span style=\"color: #e6db74;\">\"$OCI_PRIVATE_KEY\"</span> | tee /ssh/oci_private_key.pem\n      - chmod <span style=\"color: #ae81ff;\">644</span> /ssh/*\n    <span style=\"color: #66d9ef;\">when</span>:\n      <span style=\"color: #66d9ef;\">event</span>:\n      - pull_request\n\n[...]\n\n<span style=\"color: #66d9ef;\">volumes</span>:\n  - <span style=\"color: #66d9ef;\">name</span>: cache\n    <span style=\"color: #66d9ef;\">temp</span>: {}\n</code></pre></div><p>This step takes the contents of some secrets, and then places them into files. In the above, these are my Drone SSH keys, and also the OCI GPG private key. These are placed in a <a href=\"https://docs.drone.io/pipeline/docker/syntax/volumes/\">volume</a>. A volume is a shared directory/path that can be made available to other steps within a pipeline.</p>\n<p>For Oracle Cloud Infrastructure, the GPG key is required to authenticate against the API, whereas the SSH keys (specifically the public key) are used in the <code>cloud-init</code>/user data to bootstrap the instances. By default they do not allow password-based authentication to login via SSH, so they need some form of SSH key to allow you to login.</p>\n<p>An example of using this is below: -</p>\n<div class=\"highlight\"><pre><code class=\"language-yaml\">- <span style=\"color: #66d9ef;\">name</span>: Terraform Plan\n  <span style=\"color: #66d9ef;\">image</span>: jmccann/drone-terraform:latest\n  <span style=\"color: #66d9ef;\">settings</span>:\n    <span style=\"color: #66d9ef;\">actions</span>:\n      - validate\n      - plan\n    <span style=\"color: #66d9ef;\">vars</span>:\n      <span style=\"color: #66d9ef;\">ssh_public_key</span>: <span style=\"color: #e6db74;\">\"/ssh/id_rsa.pub\"</span>\n  <span style=\"color: #66d9ef;\">environment</span>:\n      <span style=\"color: #66d9ef;\">TF_VAR_tenancy_ocid</span>: \n        <span style=\"color: #66d9ef;\">from_secret</span>: oci_tenancy_ocid\n      <span style=\"color: #66d9ef;\">TF_VAR_user_ocid</span>: \n        <span style=\"color: #66d9ef;\">from_secret</span>: oci_user_ocid\n      <span style=\"color: #66d9ef;\">TF_VAR_compartment_ocid</span>: \n        <span style=\"color: #66d9ef;\">from_secret</span>: oci_compartment_ocid\n      <span style=\"color: #66d9ef;\">TF_VAR_fingerprint</span>: \n        <span style=\"color: #66d9ef;\">from_secret</span>: oci_fingerprint\n      <span style=\"color: #66d9ef;\">TF_VAR_private_key_path</span>: <span style=\"color: #e6db74;\">\"/ssh/oci_private_key.pem\"</span>\n  <span style=\"color: #66d9ef;\">volumes</span>:\n    - <span style=\"color: #66d9ef;\">name</span>: cache\n      <span style=\"color: #66d9ef;\">path</span>: /ssh\n  <span style=\"color: #66d9ef;\">when</span>:\n    <span style=\"color: #66d9ef;\">event</span>:\n    - pull_request\n</code></pre></div><p>As you can see, the SSH key path is supplied as a variable. We also supply the OCI private key path as a <code>TF_VAR</code> environment variable. The most important part here is the <code>volumes</code> section, as without this the keys created in the previous step would not be available.</p>\n<p>Volumes could be used in many different ways (e.g. cached dependencies, creating build artifacts and pushing them). In this case it make files available between steps, allowing authentication to certain providers.</p>\n<p>The same step is used in my Lab Terraform when creating Proxmox virtual machines. This is because <a href=\"https://cloudinit.readthedocs.io/en/latest/\">cloud-init</a> in Proxmox requires adding files directly to the Proxmox host&rsquo;s file system (rather than being stored in an API). In my case, I use SSH/SCP within Terraform to transfer the files to the Proxmox host(s), using the Drone SSH keys for authentication.</p>\n<h2 id=\"remote-state-backend-with-consul\">Remote State Backend with Consul</h2>\n<p>While not specific to Drone, using some form of Remote State Backend within Terraform allows the following: -</p>\n<ul>\n<li>A central place to source state between Drone jobs and local Terraform testing</li>\n<li>Using Remote State as a data source in Terraform code</li>\n<li>State Locking - avoids multiple jobs/people applying changes at the same time (and potentially breaking each others changes)\n<ul>\n<li>Not all backends support this, and some require a separate backend for locking (e.g. AWS S3 for state storage, and DynamoDB for state locking)</li>\n</ul>\n</li>\n<li>Most importantly, it means Drone does not need to write to a <code>terraform.tfstate</code> file in the repository and push it back to the repository after changes are made</li>\n</ul>\n<p>The last point is especially pertinent, as without this the following steps would be required: -</p>\n<ul>\n<li>Create a cache/state volume in the pipeline</li>\n<li>Make the Terraform Drone plugin place state files in the volume</li>\n<li>Run a step after each Terraform Apply stage to add, commit and push changes back to the code repository\n<ul>\n<li>This also means giving Drone access to push (and not just pull/clone rights) access to the repository</li>\n</ul>\n</li>\n</ul>\n<p>Instead, using a Remote State Backend means none of these extra steps are required. Many different options for Backends are available (e.g. AWS S3, Azure Blob Storage, etcd, Postgres), but I chose Consul as I already run Consul for <a href=\"https://yetiops.net/posts/prometheus-consul-node_exporter/\">Prometheus Service Discovery</a>.</p>\n<p>Setting up this backend looks like the below: -</p>\n<div class=\"highlight\"><pre><code class=\"language-hcl\"><span style=\"color: #66d9ef;\">terraform</span> {\n  <span style=\"color: #66d9ef;\">backend</span> <span style=\"color: #e6db74;\">\"consul\"</span> {\n    address <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"consul.noisepalace.co.uk\"</span>\n    scheme  <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"https\"</span>\n    path    <span style=\"color: #f92672;\">=</span> <span style=\"color: #e6db74;\">\"terraform/oraclecloud/oci\"</span>\n  }\n}\n</code></pre></div><p>The path structure is arbitrary. I decided to use a <code>$APPLICATION/$PROVIDER/$PURPOSE</code> structure, but you could name each one after characters in Star Wars or Transformers if you wished! This stores state in the Consul KV store, as shown below: -</p>\n<p><img alt=\"Drone Terraform Consul KV store\" src=\"https://yetiops.net/img/homeinfra/drone-terraform-consul.png\" /></p>\n<h2 id=\"demonstration\">Demonstration</h2>\n<p>The below video is a demonstration of making a change to the Terraform repository and committing it. In this step I am going to create a DNS record in Cloudflare: -</p>\n\n<div style=\"padding-bottom: 56.25%; height: 0; overflow: hidden;\">\n  \n</div>\n\n<h2 id=\"summary\">Summary</h2>\n<p>In this, we have seen how to can make use of Drone to apply Terraform configuration.</p>\n<p>This has also shown how we can make use of Consul to provide a consistent Backend for Terraform, reducing the need for additional steps to manage Terraform state files with Drone.</p>\n<p>In the next post, I&rsquo;m going to cover using Drone to build Go releases.</p>"
        }
      ]
    }
  },
  {
    "blog": {
      "title": "Adventurist Blog",
      "by": "Tom Jones",
      "url": "https://adventurist.me/page/1",
      "feed": "https://adventurist.me/feed.xml",
      "description": "FreeBSD, electronics engineering, hacker camps and fests. Using serial\nconsole for out-of-band server management (whitebox builds)",
      "section": "Homelab"
    },
    "entry": {
      "title": "Some ideas I picked from the electromagnetic fields",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://adventurist.me/feed.xml",
        "value": "Some ideas I picked from the electromagnetic fields"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://adventurist.me/posts/00314"
        }
      ],
      "link": "https://adventurist.me/posts/00314",
      "summary": "<p>\n I made it to and from the\n <a href=\"https://www.emfcamp.org/\">\n  Electromagnetic Field\n </a>\n . It was quite an\nexperience to return to a hacker large event after so many years.\n</p>\n<p>\n A real review of the event will appear in the FreeBSD Journal this summer and I\nrambled a little at the end of BSDNow 459.\n</p>\n<p>\n I don't think I could have articulated before hand exactly how much I missed\nthe massive influx of energy being around people doing things gives you. To be\nhonest, it probably explains why I spent so many years running things myself.\nThe sheer magic of other people doing things seems to relax my brain and lets\nit fill up to the brim with new ideas.\n</p>\n<p>\n In the vein of \"“Make 50 of Something\" (\n <a href=\"http://vihart.com/fifty-fizzbuzzes/\">\n  which I learned about from Vi Hart\nmaking 50 fizzbuzzers\n </a>\n ), I thought it was finally time to write\ndown the ideas in the aftermath of the event and have a record of them.\n</p>\n<p>\n 50 is a lot of things, but I don't think this list actually captures everything\nthat popped into my head. Much of this list is ideas I have been having over\nthe last decade of going to hacker events, but unexecuted ideas can still be\ngood.\n</p>\n<p>\n <a href=\"https://adventurist.me/images/emfcamp2022-notebook.jpg\">\n  <img src=\"https://adventurist.me/imagessmall/emfcamp2022-notebook.jpg\" />\n </a>\n</p>\n<ol>\n <li>\n  ID Badge\n </li>\n <li>\n  Buckfast FM\n </li>\n <li>\n  Buckfast FM badge\n </li>\n <li>\n  BBS serial network\n </li>\n <li>\n  Government style news distribution network with backdoor leading to a bbs\n </li>\n <li>\n  TIC-80 simulator for the badge\n </li>\n <li>\n  shit camera ID printer\n </li>\n <li>\n  badge tamogotchi thing\n </li>\n <li>\n  \"Cyberman\" led outfit\n </li>\n <li>\n  kit dome of trees\n </li>\n <li>\n  web bbs\n </li>\n <li>\n  retro bbs\n </li>\n <li>\n  web bbs serial links to esp consoles\n </li>\n <li>\n  demo display on a dome\n </li>\n <li>\n  longest serial transmission competition\n </li>\n <li>\n  internet of buckets\n </li>\n <li>\n  network of floaty led things in lake\n </li>\n <li>\n  posters!\n </li>\n <li>\n  stickers!\n </li>\n <li>\n  sticker: The Internet is Bullshit\n </li>\n <li>\n  sticker: Computers are a fuck\n </li>\n <li>\n  sticker: \"I'll drive if you feed me cheese\"\n </li>\n <li>\n  sticker: a big pile of tofu\n </li>\n <li>\n  talk: 10 years of Scotland as performance art\n </li>\n <li>\n  Old Unix BBS\n </li>\n <li>\n  something targetting the badge\n </li>\n <li>\n  \"set\" mainframe backdrop\n </li>\n <li>\n  weather reports\n </li>\n <li>\n  Scotcon TV\n </li>\n <li>\n  An actual good computer book shop\n </li>\n <li>\n  BSD meet up\n </li>\n <li>\n  hacker breakfast\n </li>\n <li>\n  'drugwars' with real location integration\n </li>\n <li>\n  CTF coffee puzzle\n </li>\n <li>\n  folding bikes!\n </li>\n <li>\n  portraits with a camera\n </li>\n <li>\n  portraits with a paint brush\n </li>\n <li>\n  computer church\n </li>\n <li>\n  beacon hunt\n </li>\n <li>\n  demo party\n </li>\n <li>\n  paiting party\n </li>\n <li>\n  talk: Learning a place by drawing its buildings\n </li>\n <li>\n  SBC colo\n </li>\n <li>\n  deerocracy\n </li>\n <li>\n  tshirts\n </li>\n <li>\n  sticker: No one hsa found a good use for a networked computer\n </li>\n <li>\n  sketching workshop\n </li>\n <li>\n  thicknet, network\n </li>\n <li>\n  industrial quantities of mauve\n </li>\n <li>\n  $5 electronics macro photo workshop\n </li>\n <li>\n  silent journalling with [tj]\n </li>\n</ol>\n<p>\n Yes, It is super vague. There are thousands of words of explanation behind some\nof these. That you will have to invent for yourself.\n</p>\n<p>\n Steal what you want, I won't remember publishing this and will love seeing your\nimplementation.\n</p>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://adventurist.me/feed.xml",
        "value": "<p>\n I made it to and from the\n <a href=\"https://www.emfcamp.org/\">\n  Electromagnetic Field\n </a>\n . It was quite an\nexperience to return to a hacker large event after so many years.\n</p>\n<p>\n A real review of the event will appear in the FreeBSD Journal this summer and I\nrambled a little at the end of BSDNow 459.\n</p>\n<p>\n I don't think I could have articulated before hand exactly how much I missed\nthe massive influx of energy being around people doing things gives you. To be\nhonest, it probably explains why I spent so many years running things myself.\nThe sheer magic of other people doing things seems to relax my brain and lets\nit fill up to the brim with new ideas.\n</p>\n<p>\n In the vein of \"“Make 50 of Something\" (\n <a href=\"http://vihart.com/fifty-fizzbuzzes/\">\n  which I learned about from Vi Hart\nmaking 50 fizzbuzzers\n </a>\n ), I thought it was finally time to write\ndown the ideas in the aftermath of the event and have a record of them.\n</p>\n<p>\n 50 is a lot of things, but I don't think this list actually captures everything\nthat popped into my head. Much of this list is ideas I have been having over\nthe last decade of going to hacker events, but unexecuted ideas can still be\ngood.\n</p>\n<p>\n <a href=\"https://adventurist.me/images/emfcamp2022-notebook.jpg\">\n  <img src=\"https://adventurist.me/imagessmall/emfcamp2022-notebook.jpg\" />\n </a>\n</p>\n<ol>\n <li>\n  ID Badge\n </li>\n <li>\n  Buckfast FM\n </li>\n <li>\n  Buckfast FM badge\n </li>\n <li>\n  BBS serial network\n </li>\n <li>\n  Government style news distribution network with backdoor leading to a bbs\n </li>\n <li>\n  TIC-80 simulator for the badge\n </li>\n <li>\n  shit camera ID printer\n </li>\n <li>\n  badge tamogotchi thing\n </li>\n <li>\n  \"Cyberman\" led outfit\n </li>\n <li>\n  kit dome of trees\n </li>\n <li>\n  web bbs\n </li>\n <li>\n  retro bbs\n </li>\n <li>\n  web bbs serial links to esp consoles\n </li>\n <li>\n  demo display on a dome\n </li>\n <li>\n  longest serial transmission competition\n </li>\n <li>\n  internet of buckets\n </li>\n <li>\n  network of floaty led things in lake\n </li>\n <li>\n  posters!\n </li>\n <li>\n  stickers!\n </li>\n <li>\n  sticker: The Internet is Bullshit\n </li>\n <li>\n  sticker: Computers are a fuck\n </li>\n <li>\n  sticker: \"I'll drive if you feed me cheese\"\n </li>\n <li>\n  sticker: a big pile of tofu\n </li>\n <li>\n  talk: 10 years of Scotland as performance art\n </li>\n <li>\n  Old Unix BBS\n </li>\n <li>\n  something targetting the badge\n </li>\n <li>\n  \"set\" mainframe backdrop\n </li>\n <li>\n  weather reports\n </li>\n <li>\n  Scotcon TV\n </li>\n <li>\n  An actual good computer book shop\n </li>\n <li>\n  BSD meet up\n </li>\n <li>\n  hacker breakfast\n </li>\n <li>\n  'drugwars' with real location integration\n </li>\n <li>\n  CTF coffee puzzle\n </li>\n <li>\n  folding bikes!\n </li>\n <li>\n  portraits with a camera\n </li>\n <li>\n  portraits with a paint brush\n </li>\n <li>\n  computer church\n </li>\n <li>\n  beacon hunt\n </li>\n <li>\n  demo party\n </li>\n <li>\n  paiting party\n </li>\n <li>\n  talk: Learning a place by drawing its buildings\n </li>\n <li>\n  SBC colo\n </li>\n <li>\n  deerocracy\n </li>\n <li>\n  tshirts\n </li>\n <li>\n  sticker: No one hsa found a good use for a networked computer\n </li>\n <li>\n  sketching workshop\n </li>\n <li>\n  thicknet, network\n </li>\n <li>\n  industrial quantities of mauve\n </li>\n <li>\n  $5 electronics macro photo workshop\n </li>\n <li>\n  silent journalling with [tj]\n </li>\n</ol>\n<p>\n Yes, It is super vague. There are thousands of words of explanation behind some\nof these. That you will have to invent for yourself.\n</p>\n<p>\n Steal what you want, I won't remember publishing this and will love seeing your\nimplementation.\n</p>"
      },
      "id": "https://adventurist.me/posts/00314",
      "guidislink": false,
      "published": "Thu, 09 Jun 2022 00:00:00 +0000",
      "published_parsed": [
        2022,
        6,
        9,
        0,
        0,
        0,
        3,
        160,
        0
      ]
    }
  },
  {
    "blog": {
      "title": "Solène Rapenne",
      "url": "https://dataswamp.org/~solene/",
      "feed": "https://dataswamp.org/~solene/rss.xml",
      "description": "OpenBSD developer solene@. Also some posts on NixOS, reproducible builds,\ngame engines...",
      "section": "OpenBSD"
    },
    "entry": {
      "title": "The Old Computer Challenge V2: day 1",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://dataswamp.org/~solene/rss.xml",
        "value": "The Old Computer Challenge V2: day 1"
      },
      "summary": "<pre># Introduction\n\nToday is the beginning of the 2022 Old Computer Challenge, for a week I am not restricted to one hour of Internet access per day.\n\n=> https://dataswamp.org/~solene/2022-07-01-oldcomputerchallenge-v2-rtc.html Old Computer Challenge V2 announcement\n\n# How do I account time?\n\nFor now, I turned off my smartphone Wi-Fi because it would be hard to account its time.\n\nMy main laptop is using the very nice script from our community member prahou.\n\nThe script design is smart, it's accounting time and displaying time consumed, it can be described as a machine state like this:\n\n```trying to describe a machine state\n\n   +------------+                    +----------------------------+\n   | wait for   |                    | Accounting time for today  |\n   | input      |  Type Enter        | Internet is enabled        |\n   |            |------------------->|                            |\n   | Internet   |                    | display time used          |\n   | offline    |                    | today                      |\n   +------------+                    +----------------------------+\n          ^                                         v\n          |                       press ctrl+C      |\n          |       (which is trapped to run a func)  |\n          +-----------------------------------------+\n```\n\nAs the way to disable / enable internet is specific to every one, the script has two empty fuctions: NETON and NETOFF, they enable or disable Internet access.  On my Linux computer I found an easy way to achieve this by adding a bogus default route with a metric 1, bypassing my default route.  Because the default route doesn't work my system can't reach the Internet, but it let my LAN in a working state.\n\n=> https://perso.pw/internet-accounting.sh My own version of prahou's script (I made some little changes)\n\n# How's life?\n\nSo far, it's easy to remember I don't have Internet all the time, but with my Internet usage it works fine.  I use the script to \"start\" Internet, check my emails, read IRC channels and reply, and then I disconnect.  By using small amount of time, I can achieve most of my needs in less than a minute.  However, that wouldn't be practical if I had to download anything big, and people with a fast Internet access (= not me) would have an advantage.\n\nMy guess about this first day being easy is that as I don't use any streaming service, I don't need to be connected all the time.  All my data are saved locally, and most of my communication needs can be done asynchronously.  Even publishing this blog post shouldn't consume more than 20 seconds.\n\n# Let's go for a week\n\nI suppose it will be easy to forget about limited Internet time, so it will be best for me to run the accounting script in a terminal (disabling Internet until I manually accept to enable it), and think a bit ahead if I will need more time later so I can be more conservative about time usage.\n\nSo far, it's a great experience I enjoy a lot.  I hope other participant will enjoy it as much as I do.  We will start gathering and aggregating reports soon, so you could enjoy all the reports from our community.\n\n# It's not late to join\n\nDespite the challenge officially started today (10th July), it's not late to start it yourself.  The important is to have fun, if you want to try, you could just use a chronometer and see if you could hold with only 60 minutes a day.\n</pre>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://dataswamp.org/~solene/rss.xml",
        "value": "<pre># Introduction\n\nToday is the beginning of the 2022 Old Computer Challenge, for a week I am not restricted to one hour of Internet access per day.\n\n=> https://dataswamp.org/~solene/2022-07-01-oldcomputerchallenge-v2-rtc.html Old Computer Challenge V2 announcement\n\n# How do I account time?\n\nFor now, I turned off my smartphone Wi-Fi because it would be hard to account its time.\n\nMy main laptop is using the very nice script from our community member prahou.\n\nThe script design is smart, it's accounting time and displaying time consumed, it can be described as a machine state like this:\n\n```trying to describe a machine state\n\n   +------------+                    +----------------------------+\n   | wait for   |                    | Accounting time for today  |\n   | input      |  Type Enter        | Internet is enabled        |\n   |            |------------------->|                            |\n   | Internet   |                    | display time used          |\n   | offline    |                    | today                      |\n   +------------+                    +----------------------------+\n          ^                                         v\n          |                       press ctrl+C      |\n          |       (which is trapped to run a func)  |\n          +-----------------------------------------+\n```\n\nAs the way to disable / enable internet is specific to every one, the script has two empty fuctions: NETON and NETOFF, they enable or disable Internet access.  On my Linux computer I found an easy way to achieve this by adding a bogus default route with a metric 1, bypassing my default route.  Because the default route doesn't work my system can't reach the Internet, but it let my LAN in a working state.\n\n=> https://perso.pw/internet-accounting.sh My own version of prahou's script (I made some little changes)\n\n# How's life?\n\nSo far, it's easy to remember I don't have Internet all the time, but with my Internet usage it works fine.  I use the script to \"start\" Internet, check my emails, read IRC channels and reply, and then I disconnect.  By using small amount of time, I can achieve most of my needs in less than a minute.  However, that wouldn't be practical if I had to download anything big, and people with a fast Internet access (= not me) would have an advantage.\n\nMy guess about this first day being easy is that as I don't use any streaming service, I don't need to be connected all the time.  All my data are saved locally, and most of my communication needs can be done asynchronously.  Even publishing this blog post shouldn't consume more than 20 seconds.\n\n# Let's go for a week\n\nI suppose it will be easy to forget about limited Internet time, so it will be best for me to run the accounting script in a terminal (disabling Internet until I manually accept to enable it), and think a bit ahead if I will need more time later so I can be more conservative about time usage.\n\nSo far, it's a great experience I enjoy a lot.  I hope other participant will enjoy it as much as I do.  We will start gathering and aggregating reports soon, so you could enjoy all the reports from our community.\n\n# It's not late to join\n\nDespite the challenge officially started today (10th July), it's not late to start it yourself.  The important is to have fun, if you want to try, you could just use a chronometer and see if you could hold with only 60 minutes a day.\n</pre>"
      },
      "id": "https://dataswamp.org/~solene/2022-07-10-old-computer-challenge-v2-day1.html",
      "guidislink": true,
      "link": "https://dataswamp.org/~solene/2022-07-10-old-computer-challenge-v2-day1.html",
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://dataswamp.org/~solene/2022-07-10-old-computer-challenge-v2-day1.html"
        }
      ],
      "published": "Sun, 10 Jul 2022 00:00:00 GMT",
      "published_parsed": [
        2022,
        7,
        10,
        0,
        0,
        0,
        6,
        191,
        0
      ]
    }
  },
  {
    "blog": {
      "title": "Doing stupid things (with packets and OpenBSD)",
      "url": "https://doing-stupid-things.as59645.net/",
      "feed": "https://doing-stupid-things.as59645.net/feed.xml",
      "description": "Sometimes, it is fun to do stupid things. This blog documents things done on\nAS59645 to run a (mostly) OpenBSD only, self-hosted AS \"the old way\". Most\ncertainly NSFP (Not Safe for Production) and never reasonable.",
      "section": "OpenBSD"
    },
    "entry": {
      "title": "13 Propositions on an Internet for a Burning World (Part 13)",
      "title_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://doing-stupid-things.as59645.net/feed.xml",
        "value": "13 Propositions on an Internet for a Burning World (Part 13)"
      },
      "links": [
        {
          "href": "https://doing-stupid-things.as59645.net/burning/world/resillience/2022/07/09/propositions-part-13.html",
          "rel": "alternate",
          "type": "text/html",
          "title": "13 Propositions on an Internet for a Burning World (Part 13)"
        }
      ],
      "link": "https://doing-stupid-things.as59645.net/burning/world/resillience/2022/07/09/propositions-part-13.html",
      "published": "2022-07-09T15:26:12+02:00",
      "published_parsed": [
        2022,
        7,
        9,
        13,
        26,
        12,
        5,
        190,
        0
      ],
      "updated": "2022-07-09T15:26:12+02:00",
      "updated_parsed": [
        2022,
        7,
        9,
        13,
        26,
        12,
        5,
        190,
        0
      ],
      "id": "https://doing-stupid-things.as59645.net/burning/world/resillience/2022/07/09/propositions-part-13",
      "guidislink": false,
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://doing-stupid-things.as59645.net/burning/world/resillience/2022/07/09/propositions-part-13.html",
          "value": "<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>OpenBSD version: Not relevant here...\nArch:            ?\nNSFP:            Well...\n</code></pre></div></div>\n\n<p>For some wired reason, humans have an uncanny tendency of reacting to crises not with the appropriate unification and ‘surviving together’, but with splintering apart an ‘us vs. them’ mentality.\nWith the <a href=\"https://knowyourmeme.com/memes/events/neuland\">‘neuland’</a> of the Internet being around for a couple of decades now, traditional leadership and governance people discovered this new vast area for themselves and their ideas.\nHumans being humans, though, people confronted with something new will try to pattern-match it to what they already know.\nIf we are talking international politics, what is known are terms like ‘borders’ and ‘sovereignty’.</p>\n\n<p>Hence, what that got us is the new flying buzzword <em>‘digital sovereignty’</em>. \nThis <a href=\"https://cybersec4europe.eu/wp-content/uploads/2019/11/Governance-Challenges-for-European-CyberSecurity-Policy_-Stakeholders-Views_V.Def_.pdf\">pressing issue</a> in the policy arena is usually understood as <em>‘ensuring that a state can exert policy on the (IT) systems used by its constituents, while ensuring that only their own policy is applied to them.’</em>\nThe classical example of attempts to realize this with policy is most likely the ongoing discussion of the `Safe Harbor’ agreement, or whatever the name of the <a href=\"https://en.wikipedia.org/wiki/EU%E2%80%93US_Privacy_Shield\">current incarnation</a> is.\nA similar, more technical approach, is <a href=\"https://en.wikipedia.org/wiki/Schengen_Routing\">Schengen Routing</a>, i.e., an attempt to make sure packets from European users do not leave the EU.</p>\n\n<p>What all these approaches have in common is that they, ultimately, dream of a cozy little ‘Internet’ within the boundaries of individual nation states or sets of such.\nEuropeans are usually rather quick to be judgemental about countries installing cryptographic backdoors and running national firewalls for censorship; \nHowever, will quickly, either under the disguise of either <a href=\"https://eit.europa.eu/sites/default/files/eit-digital-data-sovereignty-full-report.pdf\">digital sovereignty</a>, or under the pretense of <a href=\"https://www.patrick-breyer.de/en/posts/messaging-and-chat-control/\">protecting $group_of_vulnerable_people</a> happily pflock to policies yielding the same results.\nAt this point we do not want to pass judgement on these approaches, no matter where they take place; What we would like to point out, though, is that these processes align rather well with our previous observation that <a href=\"https://doing-stupid-things.as59645.net/burning/world/resillience/2022/07/08/propositions-part-12.html\"><em>“the Internet will be falling apart”</em></a>.</p>\n\n<p>Still, with digital sovereignty being juggled around so frequently in the context of applying policies and control, we believe that another important part is usually missed in the face of a burning world.\nIn fact, we claim:</p>\n\n<h1 id=\"proposition-13\">Proposition 13</h1>\n<p><em>“Digital sovereignty is being used wrong.”</em></p>\n\n<p>Of course, we would all like to live in a world that is <em>not</em> falling apart, and where defending the united, open, and global Internet from attempts to segment and nationalize it is the most pressing issue.\nHowever, as much as the happy engineers in us that grew up on and with the Internet want to just see packets flow, given the state of our world we also have to consider a much more fundamental meaning of sovereignty, which is usually missed:\nThe ability to (re)build and maintain one’s infrastructure independent of another party.</p>\n\n<p>And this is something that just continues to get harder and harder.\nComputers don’t live forever. Capacitors age, up to the point where they can no longer power a system (shoutout to everyone who had a suprise power loss in a data with <em>a lot</em> of legacy systems).\nHard disks eventually die.\nSSDs have an explicit best-before, usually explicitly written in stone er… firmware, denominated in write cycles.</p>\n\n<p>We all like to tell stories of those Department of Defense contractors that keep buying old DEC Alpha equipment on online market places for horrendous prices.\nBut the truth behind that is that a major part of our digital infrastructure hinges on a steady supply of spare and replacement parts, which can not be easily produced in a world burned to the ground.\nThat nice solar energy farm over there?\nWhat happens if the mainboard in the (1, 2, 3, it is only a matter of time) controllers just dies?\nUp to a point you may be able to repair by salvaging things [scattered in the world around us].\nBut ultimately, we might get to a point where we might have to <em>replace</em> systems all together (or, say, just their harddrive).\nAnd then, the <em>hardware</em> problem perpetuates to the software.\nWhere can we <em>get</em> the right controll software, system documentation, or firmware and how do we make it run on a computer it was never intended to run on, all the while the vendor who initially build is lays in the ashes of our burning world?</p>\n\n<p>One might argue that this is not an issue in a globalized world, and our world will stay… fine.\nHowever, as we learned earlier this year, all it takes is a stuck ship and a global pandemic to give us a free preview into such a future world.\nAll of a sudden, we could see how the world can be when it may take [months or years][sth] for new and replacement systems to arrive.\nAnd this will only get worse, with more and more parts of our world burning down all around us.</p>\n\n<p>Hence, in a burning world, it may be essential to have the know how to keep systems running wide spread and locally available.\nAnd yes, this includes questions like <a href=\"https://dataswamp.org/~solene/2021-10-21-huge-disaster-recovery-plan.html\">open(!) and publicly available(!), ideally, open source software and documentation</a>.\nOtherwise, computers may just become rather expensive (and, to be honest, actually worse) bricks.</p>\n\n<p>Also, going back to the sum of the earlier propositions, the policy aspect may even be secondary.\nIn the end it is about running systems, providing services, and caring for users. Everywhere. <a href=\"https://dataswamp.org/~solene/2021-10-21-huge-disaster-recovery-plan.html\">As long as we can rebuild</a>.</p>\n\n<h1 id=\"what-now\">What now?</h1>\n\n<p>Over the past 13 days we took you along for a ride through <em>‘13 Propositions for a Burning World’</em>, thinking about a resilient and sustainable Internet, which should be run with care for its users and the infrastructure itself. \nThey might be overly bold, lack concrete solutions, and paint a disturbingly dire picture of the world. (And we hope you are not <em>too</em> depressed after reading them.)\nStill, given the state of the world, we claim that we are past the point of raising awareness and hiding behind ‘they would never’;\nWe can no longer risk staying complacent in the hopes for a better future.\nWe have to talk about these issues <em>now</em> and find tangible solutions.\nThe future will be bleak if we do not make it better, and whether the world goes down in flames or not, preparation is better than reaction.</p>\n\n<p>Our first gut reaction, roughly, translates to <em>“Computers were a mistake. Learn to ride a horse and grow your own food.”</em>\nBut that can not be the answer, not for the the billions of people going with us into the shifts to come.\nAfter all, we are system, network, routing, and many more… engineers.<br />\nAnd calling yourself an engineer <a href=\"https://en.wikipedia.org/wiki/Ritual_of_the_Calling_of_an_Engineer\">comes with a responsibility</a>;<br />\nA responsibility to build a better world for everyone.<br />\nAnd a responsibility to keep trying to make the world better, even if it looks bleak.</p>\n\n<p>So, to fulfill the ultimate cliché of people who grew up on the Internet, let us close with a Star Trek quote:</p>\n\n<p><em>“It may be the warriors who get the glory, but it’s the engineers who build societies.”</em><br />\n<em>- B’Elanna Torres</em></p>"
        }
      ],
      "summary": "OpenBSD version: Not relevant here... Arch: ? NSFP: Well...",
      "authors": [
        {
          "name": ""
        }
      ],
      "author_detail": {
        "name": ""
      },
      "author": "",
      "tags": [
        {
          "term": "burning",
          "scheme": null,
          "label": null
        },
        {
          "term": "world",
          "scheme": null,
          "label": null
        },
        {
          "term": "resillience",
          "scheme": null,
          "label": null
        }
      ],
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://doing-stupid-things.as59645.net/feed.xml",
        "value": "OpenBSD version: Not relevant here... Arch: ? NSFP: Well..."
      }
    }
  },
  {
    "blog": {
      "title": "Data, tech, and sometimes Nutella",
      "by": "Vicky Boykis",
      "url": "https://vickiboykis.com",
      "feed": "https://vickiboykis.com/index.xml",
      "description": "Some social insights into IT industry, articles about privacy in modern\nworld. Lots of links to Hacker News, Reddit trends, some posts about\nFacebook, some posts about Python.",
      "section": "Other IT related topics"
    },
    "entry": {
      "title": "On owning a software problem",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://vickiboykis.com/index.xml",
        "value": "On owning a software problem"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://veekaybee.github.io/2022/02/21/on-owning-a-software-problem/"
        }
      ],
      "link": "https://veekaybee.github.io/2022/02/21/on-owning-a-software-problem/",
      "published": "Mon, 21 Feb 2022 00:00:00 +0000",
      "published_parsed": [
        2022,
        2,
        21,
        0,
        0,
        0,
        0,
        52,
        0
      ],
      "id": "https://veekaybee.github.io/2022/02/21/on-owning-a-software-problem/",
      "guidislink": false,
      "summary": "This weekend, I saw a tweet that really resonated with me, and judging by the comments, resonated with a lot of others, too.\nIt reads,\n&ldquo;My buddy is an electrician and told me a few months ago that he always leaves the screws in a vertical position on jobs as a sign of craftsmanship. Been thinking ever since what my “vertical screws” equivalent is for product design.&rdquo;\nThis is so great.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://vickiboykis.com/index.xml",
        "value": "This weekend, I saw a tweet that really resonated with me, and judging by the comments, resonated with a lot of others, too.\nIt reads,\n&ldquo;My buddy is an electrician and told me a few months ago that he always leaves the screws in a vertical position on jobs as a sign of craftsmanship. Been thinking ever since what my “vertical screws” equivalent is for product design.&rdquo;\nThis is so great."
      }
    }
  },
  {
    "blog": {
      "title": "/dev/lawyer",
      "by": "Kyle E. Mitchell",
      "url": "https://writing.kemitchell.com/",
      "feed": "https://writing.kemitchell.com/atom.xml",
      "description": "A blog by a lawyer very knowledgeable of open source licenses. Kyle has\nwritten several niche licenses that try to be better than the existing FOSS\nones. The blog is frequently updated with articles on open source\nsustainability, free work and profiteering by industry from FOSS\ncontributors. There are also links to other blogs in the same field.",
      "section": "Other IT related topics"
    },
    "entry": {
      "title": "Time Off Summer ’22",
      "title_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://writing.kemitchell.com/atom.xml",
        "value": "Time Off Summer ’22"
      },
      "links": [
        {
          "href": "https://writing.kemitchell.com/2022/07/04/Time-Off",
          "rel": "alternate",
          "type": "text/html",
          "title": "Time Off Summer ’22"
        }
      ],
      "link": "https://writing.kemitchell.com/2022/07/04/Time-Off",
      "published": "2022-07-04T21:46:46+00:00",
      "published_parsed": [
        2022,
        7,
        4,
        21,
        46,
        46,
        0,
        185,
        0
      ],
      "updated": "2022-07-04T21:46:46+00:00",
      "updated_parsed": [
        2022,
        7,
        4,
        21,
        46,
        46,
        0,
        185,
        0
      ],
      "id": "https://writing.kemitchell.com/2022/07/04/Time-Off",
      "guidislink": false,
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://writing.kemitchell.com/2022/07/04/Time-Off",
          "value": "<p>I am taking the first two full weeks of August off, from Sunday, August 7 through Saturday, August 20.  Feel free to keep e-mailing me during that time, but please expect any response after I return.</p>"
        }
      ],
      "summary": "out of office August 7 through 20",
      "authors": [
        {
          "name": "Kyle E. Mitchell"
        }
      ],
      "author_detail": {
        "name": "Kyle E. Mitchell"
      },
      "author": "Kyle E. Mitchell",
      "tags": [
        {
          "term": "Law Practice",
          "scheme": null,
          "label": null
        }
      ],
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://writing.kemitchell.com/atom.xml",
        "value": "out of office August 7 through 20"
      }
    }
  },
  {
    "blog": {
      "title": "Technoglot",
      "by": "Charles K. Summers",
      "url": "https://technoglot.blogspot.com/",
      "feed": "https://technoglot.blogspot.com/feeds/posts/default",
      "description": "Long form articles from a retired computer scientist (who also writes\nfiction books sometimes).\nTopics are usually unaffected by latest trends and news which provides\na welcome change from the tiresome social networks bubble. The posts\nare typically very meditative and reflective - they are meant to be\nconversation starters, not calls to action.\nNo prior technology background is required or assumed.",
      "section": "Other IT related topics"
    },
    "entry": {
      "id": "tag:blogger.com,1999:blog-1523733021872114025.post-6881731862507946919",
      "guidislink": true,
      "link": "https://technoglot.blogspot.com/2022/07/first-time-work-hurdles-and-quandries.html",
      "published": "2022-07-01T08:27:00.001-04:00",
      "published_parsed": [
        2022,
        7,
        1,
        12,
        27,
        0,
        4,
        182,
        0
      ],
      "updated": "2022-07-01T08:27:29.420-04:00",
      "updated_parsed": [
        2022,
        7,
        1,
        12,
        27,
        29,
        4,
        182,
        0
      ],
      "tags": [
        {
          "term": "firsttime employment",
          "scheme": "http://www.blogger.com/atom/ns#",
          "label": null
        },
        {
          "term": "networking",
          "scheme": "http://www.blogger.com/atom/ns#",
          "label": null
        },
        {
          "term": "qualifications",
          "scheme": "http://www.blogger.com/atom/ns#",
          "label": null
        },
        {
          "term": "recruitment",
          "scheme": "http://www.blogger.com/atom/ns#",
          "label": null
        }
      ],
      "title": "FIrst-time work: hurdles and quandries",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://technoglot.blogspot.com/feeds/posts/default",
        "value": "FIrst-time work: hurdles and quandries"
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://technoglot.blogspot.com/feeds/posts/default",
          "value": "<p>&nbsp;</p><p>&nbsp; &nbsp; &nbsp;There is always a first time to get a paid job. There are first times for everything -- including the first breath we take after we are born. But getting a paid position is one of those types of firsts that are part of the ritual of becoming self-supporting.</p><p>&nbsp; &nbsp; &nbsp;There are two parts of this -- finding a no-experience-needed first-time position and succeeding in obtaining such.</p><p>&nbsp; &nbsp; &nbsp;For many companies, a degree (possibly Associate degree, more likely Bachelor's or above (or the non-USA equivalents)) is considered \"paper experience\". Some companies presently are starting to trade off paper experience with real-life experience. But real-life experience is rare to have that directly pertain to the skills/experience desired within a company if you are trying to find your first paid position. Sometimes, volunteer work is applicable.</p><p>&nbsp; &nbsp; &nbsp;There are places that are considered to be nests for starting paid work. How many people in high positions talk about their first jobs at McDonald's? Or as a bagger in a grocery store? Not many restaurants still wash dishes by hand -- but, once upon a dark moon, that used to be a good first time situation. My first paid position was as a neighborhood lawnmowing person (an early, very limited, entrepreneurship) followed by newspaper deliverer (on foot).</p><p>&nbsp; &nbsp; &nbsp;These jobs, associated with companies, have a couple of characteristics. First, there was a lot of turnover -- openings came up fairly frequently and if you could pass some basic requirements (cleanliness, polite demeanor, etc.) you could usually eventually get a job at one (perhaps not your first choice). Second, the pay was minimal -- in the past it was livable, in the present you had better still have other financial support.</p><p>&nbsp; &nbsp; &nbsp;But how about the positions that are considered long-term career potential?&nbsp;&nbsp;(This doesn't mean that you cannot have a long-term career at McDonald's.) First, those companies have to HAVE positions open for people with no experience. It might be in the \"mailroom\" (in electronic times, not as frequent) or janitorial areas -- but unless there is internal mobility that is not a good first step. But there may not be any non-experienced positions for the company. In that case, get your first experience at a different company where you can develop experiences that are relevant for the companies wherein you would prefer to work.</p><p>&nbsp; &nbsp; &nbsp;For the second part -- finding and succeeding in obtaining an entry-level position -- there are different gauntlets to be run depending on salary/career/social ranking. At the lowest rankings (I'm not going to list them because the titles/positions are subjective -- let's just define them as low money with low potential advancement), qualifying doesn't apply much but finding, and being allowed to apply, becomes a matter of networking and luck. In the past, it was a matter of walking to each opening that was published in the classified section of the newspaper. Now, it is primarily word-of-mouth and potentially via social job boards. But luck (which I defined, and explored, in a recent blog) plays a large role.</p><p>&nbsp; &nbsp; &nbsp;For a middle-rung position (living wage with some potential for advancement or mobility),&nbsp; old-style searches still used the classified section of newspapers but job bureaus (places where you sign up to have your resume available for distribution or job matching) were frequently used. Once again, classifieds rarely apply anymore and social networking has become a much more important areas of discovery. (Job bureaus are still used.)</p><p>&nbsp; &nbsp; &nbsp;On the high-rung side (moderately high initial salary with large potential in salary, position, and social ranking), there are still some entry-level positions. But, as I mentioned in a prior blog, there are many companies that try to demand experience for initial, first-position, jobs and many companies that require specific knowledge for these positions -- something that is truly unreasonable.</p><p>&nbsp; &nbsp; &nbsp;High-rung positions are found via direct networking or via a symbiosis of recruiters and social networking. A recruiter for such positions might receive, or need to examine, 500 potential resumes in a day. They cannot spend much more than a couple of hours looking at them as they have other duties they need to do each day. 500 resumes in 150 minutes means there is an average of 18 seconds to be spent, ON AVERAGE, per resume. I am a moderately fast reader (I can read faster but with less retention/comprehension) at about 45 words in 18 seconds. This means that, on average, the recruiter will read the first four sentences of your resume. IF something in those first four sentences (or 18 seconds of scattered keywords that catch their eye during scanning) attracts their attention then you may win more time for examination.</p><p>&nbsp; &nbsp; &nbsp;Eighteen seconds is not much time. The conclusion is to make those words count and focus on the beginning of the resume. So, if you don't have much/any experience to relate, how do you make those 45 words count in your favor? Job-relevant ACTION concluded with job-relevant RESULT. Or, job posting KEYWORD matched within relevant/reliable/consistent context.&nbsp;</p><p>&nbsp; &nbsp; &nbsp;Since you don't have (by definition within this blog) the specific experience that you hope to gain as you do the job, your action/results pairs will be associated with qualities that indicate you can succeed in gaining the knowledge needed to do the job well. Such might be aspects of focus, inventiveness, communication capabilities, organization, endurance, leadership, or other character-related aspect that can be applied to perform well in the position. They may also be associated with volunteer skill-related aspects such as pamphleting, programming, selling cookies at a table, or such.</p><p>&nbsp; &nbsp; &nbsp;A primary goal is to reduce, or eliminate, the factor of luck. This requires active networking and focus (both in application and tailoring per position). May the force be with you.</p>"
        }
      ],
      "summary": "<p>&nbsp;</p><p>&nbsp; &nbsp; &nbsp;There is always a first time to get a paid job. There are first times for everything -- including the first breath we take after we are born. But getting a paid position is one of those types of firsts that are part of the ritual of becoming self-supporting.</p><p>&nbsp; &nbsp; &nbsp;There are two parts of this -- finding a no-experience-needed first-time position and succeeding in obtaining such.</p><p>&nbsp; &nbsp; &nbsp;For many companies, a degree (possibly Associate degree, more likely Bachelor's or above (or the non-USA equivalents)) is considered \"paper experience\". Some companies presently are starting to trade off paper experience with real-life experience. But real-life experience is rare to have that directly pertain to the skills/experience desired within a company if you are trying to find your first paid position. Sometimes, volunteer work is applicable.</p><p>&nbsp; &nbsp; &nbsp;There are places that are considered to be nests for starting paid work. How many people in high positions talk about their first jobs at McDonald's? Or as a bagger in a grocery store? Not many restaurants still wash dishes by hand -- but, once upon a dark moon, that used to be a good first time situation. My first paid position was as a neighborhood lawnmowing person (an early, very limited, entrepreneurship) followed by newspaper deliverer (on foot).</p><p>&nbsp; &nbsp; &nbsp;These jobs, associated with companies, have a couple of characteristics. First, there was a lot of turnover -- openings came up fairly frequently and if you could pass some basic requirements (cleanliness, polite demeanor, etc.) you could usually eventually get a job at one (perhaps not your first choice). Second, the pay was minimal -- in the past it was livable, in the present you had better still have other financial support.</p><p>&nbsp; &nbsp; &nbsp;But how about the positions that are considered long-term career potential?&nbsp;&nbsp;(This doesn't mean that you cannot have a long-term career at McDonald's.) First, those companies have to HAVE positions open for people with no experience. It might be in the \"mailroom\" (in electronic times, not as frequent) or janitorial areas -- but unless there is internal mobility that is not a good first step. But there may not be any non-experienced positions for the company. In that case, get your first experience at a different company where you can develop experiences that are relevant for the companies wherein you would prefer to work.</p><p>&nbsp; &nbsp; &nbsp;For the second part -- finding and succeeding in obtaining an entry-level position -- there are different gauntlets to be run depending on salary/career/social ranking. At the lowest rankings (I'm not going to list them because the titles/positions are subjective -- let's just define them as low money with low potential advancement), qualifying doesn't apply much but finding, and being allowed to apply, becomes a matter of networking and luck. In the past, it was a matter of walking to each opening that was published in the classified section of the newspaper. Now, it is primarily word-of-mouth and potentially via social job boards. But luck (which I defined, and explored, in a recent blog) plays a large role.</p><p>&nbsp; &nbsp; &nbsp;For a middle-rung position (living wage with some potential for advancement or mobility),&nbsp; old-style searches still used the classified section of newspapers but job bureaus (places where you sign up to have your resume available for distribution or job matching) were frequently used. Once again, classifieds rarely apply anymore and social networking has become a much more important areas of discovery. (Job bureaus are still used.)</p><p>&nbsp; &nbsp; &nbsp;On the high-rung side (moderately high initial salary with large potential in salary, position, and social ranking), there are still some entry-level positions. But, as I mentioned in a prior blog, there are many companies that try to demand experience for initial, first-position, jobs and many companies that require specific knowledge for these positions -- something that is truly unreasonable.</p><p>&nbsp; &nbsp; &nbsp;High-rung positions are found via direct networking or via a symbiosis of recruiters and social networking. A recruiter for such positions might receive, or need to examine, 500 potential resumes in a day. They cannot spend much more than a couple of hours looking at them as they have other duties they need to do each day. 500 resumes in 150 minutes means there is an average of 18 seconds to be spent, ON AVERAGE, per resume. I am a moderately fast reader (I can read faster but with less retention/comprehension) at about 45 words in 18 seconds. This means that, on average, the recruiter will read the first four sentences of your resume. IF something in those first four sentences (or 18 seconds of scattered keywords that catch their eye during scanning) attracts their attention then you may win more time for examination.</p><p>&nbsp; &nbsp; &nbsp;Eighteen seconds is not much time. The conclusion is to make those words count and focus on the beginning of the resume. So, if you don't have much/any experience to relate, how do you make those 45 words count in your favor? Job-relevant ACTION concluded with job-relevant RESULT. Or, job posting KEYWORD matched within relevant/reliable/consistent context.&nbsp;</p><p>&nbsp; &nbsp; &nbsp;Since you don't have (by definition within this blog) the specific experience that you hope to gain as you do the job, your action/results pairs will be associated with qualities that indicate you can succeed in gaining the knowledge needed to do the job well. Such might be aspects of focus, inventiveness, communication capabilities, organization, endurance, leadership, or other character-related aspect that can be applied to perform well in the position. They may also be associated with volunteer skill-related aspects such as pamphleting, programming, selling cookies at a table, or such.</p><p>&nbsp; &nbsp; &nbsp;A primary goal is to reduce, or eliminate, the factor of luck. This requires active networking and focus (both in application and tailoring per position). May the force be with you.</p>",
      "links": [
        {
          "rel": "replies",
          "type": "application/atom+xml",
          "href": "https://technoglot.blogspot.com/feeds/6881731862507946919/comments/default",
          "title": "Post Comments"
        },
        {
          "rel": "replies",
          "type": "text/html",
          "href": "https://www.blogger.com/comment.g?blogID=1523733021872114025&postID=6881731862507946919",
          "title": "0 Comments"
        },
        {
          "rel": "edit",
          "type": "application/atom+xml",
          "href": "https://www.blogger.com/feeds/1523733021872114025/posts/default/6881731862507946919"
        },
        {
          "rel": "self",
          "type": "application/atom+xml",
          "href": "https://www.blogger.com/feeds/1523733021872114025/posts/default/6881731862507946919"
        },
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://technoglot.blogspot.com/2022/07/first-time-work-hurdles-and-quandries.html",
          "title": "FIrst-time work: hurdles and quandries"
        }
      ],
      "authors": [
        {
          "name": "CKSummers",
          "href": "http://www.blogger.com/profile/01550635140154600355",
          "email": "noreply@blogger.com"
        }
      ],
      "author_detail": {
        "name": "CKSummers",
        "href": "http://www.blogger.com/profile/01550635140154600355",
        "email": "noreply@blogger.com"
      },
      "href": "http://www.blogger.com/profile/01550635140154600355",
      "author": "CKSummers (noreply@blogger.com)",
      "gd_image": {
        "rel": "http://schemas.google.com/g/2005#thumbnail",
        "width": "16",
        "height": "16",
        "src": "https://img1.blogblog.com/img/b16-rounded.gif"
      },
      "thr_total": "0"
    }
  },
  {
    "blog": {
      "title": "The Webb Blog",
      "by": "Paul Anthony Webb",
      "url": "https://blog.webb.page/",
      "feed": "https://blog.webb.page/feed/atom",
      "description": "This author has an opinion on how the currently broken Internet can be\nfixed. Let's see what happens...",
      "section": "Other IT related topics"
    },
    "entry": {
      "title": "Things I learned from my parents",
      "title_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blog.webb.page/feed/atom",
        "value": "Things I learned from my parents"
      },
      "id": "https://blog.webb.page/2022-04-24-things-i-learned.txt",
      "guidislink": true,
      "link": "https://blog.webb.page/2022-04-24-things-i-learned.txt",
      "links": [
        {
          "href": "https://blog.webb.page/2022-04-24-things-i-learned.txt",
          "rel": "alternate",
          "type": "text/html"
        }
      ],
      "updated": "2022-04-24T00:00:00.000Z",
      "updated_parsed": [
        2022,
        4,
        24,
        0,
        0,
        0,
        6,
        114,
        0
      ],
      "summary": "It's not all bad",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blog.webb.page/feed/atom",
        "value": "It's not all bad"
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blog.webb.page/feed/atom",
          "value": "<p>When you're a kid, the people you look up to tend to be your own parent(s)/\nlegal guardian(s). The older you get, the more you realize your parents and\nother adults are very much floundering, trying to figure things out. As your\nown life experiences grow, you may look back on your childhood with resentment\nand wonder if your parents were intentional in their harm, or oblivious. I've\nspent far too much time dwelling on the past and keeping grudges. An\nunfortunate truth that's gotten me past that is realizing my parents most\nlikely do not remember how their actions and/or words affected me. While I'm\nsimmering over events that transpired a decade or more prior, they're living\ntheir lives — watching TV, doing laundry, figuring out what to eat, &amp;c.</p>\n<p>I know now I was willingly engaging in mental self-harm.</p>\n<p>Yesterday, I had a bit of back-and-forth with my father about COVID-19 in the\nfamily group chat. Mask mandates, vaccine effectiveness, &quot;narratives,&quot; &quot;COVID\nfear messaging and marketing,&quot; the works. Needless to say, the conversation\ndevolved into petty remarks so I stopped responding (ironically, my father\nstated he wanted respect for his views while gaslighting me for mine, but\nI digress).</p>\n<p>I won't lie, the conversation bothered me. It feels like I lost my father to\nFox News and conspiracy websites with dubious sources, one of which he\npresented as wholly factual and apparent proof of my idiocy.</p>\n<p>My relationship with my parents have not been the best but in recent years I've\nbeen trying to work through my issues with being close to them for the reasons\nmentioned at the top of this post. But uh, wow…it was relatively easy to slide\nback into those negative thoughts I used to have. Too easy.</p>\n<p>I awoke today, refreshed and, thinking about how I used to see my parents when\nI was a young kid. After all, I <strong>am</strong> a product of their teachings,\nintentional and otherwise.</p>\n<p>What I learned from my father:</p>\n<ul>\n<li>It takes two people to argue (the irony is not lost on me).</li>\n<li>Ensure doors and windows are closed and locked before heading to bed.</li>\n<li>There are no new problems in the world. If you have a problem, someone's\nwritten a book about it.</li>\n<li>Look someone in the eye when shaking their hand.</li>\n<li>If you have something to say, be clear. Say it with your chest.</li>\n<li>Hard work and dedication is how you get things done.</li>\n<li>Being responsible is the single best trait you can have.</li>\n<li>Games are good.</li>\n</ul>\n<p>What I learned from my mother:</p>\n<ul>\n<li>Don't ever let someone tell you you can't do something.</li>\n<li>To say &quot;I'm sorry&quot; is to say, &quot;I'm a sorry person.&quot; &quot;I apologize,&quot; is better.</li>\n<li>Art is good.</li>\n<li>Techno is good.</li>\n<li>Be yourself.</li>\n</ul>\n<p>What I learned from both my parents:</p>\n<ul>\n<li>Parenting doesn't end just because a marriage does.</li>\n<li>No one escapes consequences.</li>\n<li>Every person in the world is trying their best with the cards they're dealt.</li>\n<li>Racism sucks, is stupid, and definitely doesn't make sense. Especially since\nBlack people built this country (America).</li>\n<li>I can do anything I put my mind to.</li>\n<li>The truth shall set you free.</li>\n</ul>\n<p>We are all shaped by the experiences life either politely sends or violently\nthrows our way. Much of the sadness we feel when thinking of the past is the\nfact that the people we miss from back then are not the same people we know\nnow. Sure, they may respond to the same name, and may even have the same phone\nnumber, but we are all changing, all the time.</p>\n<p>For better or worse. 🕸</p>"
        }
      ],
      "authors": [
        {
          "name": "Paul Anthony Webb",
          "email": "paul+blog@webb.page",
          "href": "https://webb.page"
        }
      ],
      "author_detail": {
        "name": "Paul Anthony Webb",
        "email": "paul+blog@webb.page",
        "href": "https://webb.page"
      },
      "author": "Paul Anthony Webb (paul+blog@webb.page)",
      "href": "https://webb.page",
      "published_parsed": [
        2022,
        4,
        24,
        0,
        0,
        0,
        6,
        114,
        0
      ],
      "published": "2022-04-24T00:00:00.000Z"
    }
  },
  {
    "blog": {
      "title": "Bryan Cantrill and other blogs at DTrace.org",
      "url": "http://dtrace.org/blogs/",
      "feed": "http://dtrace.org/blogs/feed/",
      "description": "A brilliant technologist and a good conference speaker who worked at Sun and\nJoyent (SmartOS), and now have founded a new startup (Oxide). Other blogs at\nDTrace.org are updated less frequently but usually are also interesting.",
      "section": "Other IT related topics"
    },
    "entry": {
      "title": "Twitter Spaces, a few weeks in",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://dtrace.org/blogs/feed/",
        "value": "Twitter Spaces, a few weeks in"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://dtrace.org/blogs/bmc/2021/05/02/twitter-spaces-a-few-weeks-in/"
        }
      ],
      "link": "http://dtrace.org/blogs/bmc/2021/05/02/twitter-spaces-a-few-weeks-in/",
      "comments": "http://dtrace.org/blogs/bmc/2021/05/02/twitter-spaces-a-few-weeks-in/#comments",
      "published": "Mon, 03 May 2021 02:15:31 +0000",
      "published_parsed": [
        2021,
        5,
        3,
        2,
        15,
        31,
        0,
        123,
        0
      ],
      "authors": [
        {
          "name": "bmc"
        }
      ],
      "author": "bmc",
      "author_detail": {
        "name": "bmc"
      },
      "id": "http://dtrace.org/blogs/bmc/?p=1149",
      "guidislink": false,
      "summary": "As a kid, I listened to a lot of talk radio. This was in the 80s, before the internet &#8212; and before the AM dial became fringe. I have fond memories of falling asleep to the likes of Bruce Williams who just gave damned good, level-headed advice. It was, at essence, both optimistic and temperate: [...]",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://dtrace.org/blogs/feed/",
        "value": "As a kid, I listened to a lot of talk radio. This was in the 80s, before the internet &#8212; and before the AM dial became fringe. I have fond memories of falling asleep to the likes of Bruce Williams who just gave damned good, level-headed advice. It was, at essence, both optimistic and temperate: [...]"
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "http://dtrace.org/blogs/feed/",
          "value": "<p>As a kid, I listened to a lot of talk radio.  This was in the 80s, before the internet &#8212; and before the AM dial became fringe.  I have fond memories of falling asleep to the likes of <a href=\"https://en.wikipedia.org/wiki/Bruce_Williams_(talk_radio_host)\">Bruce Williams</a> who just gave damned good, level-headed advice.  It was, at essence, both optimistic and temperate:  a cool head to help people work through a tough spot.</p>\n<p>Nothing really replaced the call-in show:  talk radio devolved into poisonous echo chambers, while social networking gave people other outlets (too many!) to have conversations.  But these online conversations &#8212; the written word &#8212; lack something: Twitter&#8217;s tight form gives us the hot take, blogs (ahem!) give us the longer form, but it both cases, the conversations that result seem to either lose their sizzle or go thermonuclear.  Video is really great for some stuff (I have spoken about the rise of video and the <a href=\"https://www.youtube.com/watch?v=4PaWFYm0kEw\">preservation of oral tradition in software engineering</a>) &#8212; but the discussion quality there is even worse.  (When did YouTube comments become such a hellhole?!) And of course, TikTok has given us social, short-form video, which can be very entertaining, but isn&#8217;t really designed to induce any meaningful discussion.</p>\n<p>And of course, I love podcasts, and one of the reasons I was excited to <a href=\"http://dtrace.org/blogs/bmc/2019/12/02/the-soul-of-a-new-computer-company/\">start a company</a> was to get an excuse to make <a href=\"https://oxide.computer/podcast/\">the podcast that we ourselves always wanted</a>.  Podcasts are particularly great because you can <strong>do something else</strong> while listening to them:  they fill in that time when you&#8217;re doing the dishes or picking up the kids or whatever.  But podcasts obviously miss the interactivity entirely.  (Or mostly: let us not so quickly forget <a href=\"https://twitter.com/bcantrill/status/1261207048340951041\">TWiV reading my letter on-air</a>!)</p>\n<p>Into all of this, enter Clubhouse and the rise of social audio.  I had immediate Bruce Williams flashbacks, and was excited to participate.  But my choice of device makes me unwelcome in Clubhouse&#8217;s eyes:  their lack of an Android app is clearly not a mere temporary gap, but rather a deliberate deprioritization.  (I certainly honor a young company&#8217;s need to focus, but how else can one describe an exceedingly well-capitalized company adding in-app payments before addressing 75% of the market?!)  To me, the deprioritization of Android reflects Clubhouse&#8217;s deeper problem:  it is fundamentally elitist and exclusionary.  Avid Clubhouse users may claim that this was not always so, but <strong>it says it right there on the tin</strong>:  it is, at the end of the day, a <em>clubhouse</em> &#8212; not a cafe or a town square.  I personally have no interest in participating in venues that deliberately limit the participants:  I want to engage with the broadest possible cross-section, not some subset that has been manicured by circumstance or technology choice.  (For this same reason, I do not give talks unless the talk will be recorded and made freely available.)</p>\n<p>Given all of this, you can imagine my enthusiasm for Twitter Spaces: it captures the promise that I see in the medium &#8212; but addresses many of the problems with Clubhouse&#8217;s implementation.  I have been participating in them for the past few weeks and (excitingly!) found last week that I have the ability to create Spaces.  Here are my takeaways so far:</p>\n<ul>\n<li>\n<p><strong>This is an even bigger deal than I thought it was.</strong>  All of the strengths that I perceived in the medium seem to be even stronger than I thought they would be, and in particular &#8212; as with podcasts &#8212; I can have a conversation while I do something else.  It is really nice to have social networking time after which one looks back at a clean kitchen or a prepared meal!</p>\n</li>\n<li>\n<p><strong>Spaces have broadened the people I follow.</strong>  In every Space I have been in, I have come away following someone new.  I find one of the most interesting aspects of Twitter to be able to be a part of conversations and social circles that broaden our perspectives (socially, technically, or otherwise) &#8212; and Spaces takes this to a new level:  I find that I&#8217;m following people based on a comment that they make that I wouldn&#8217;t otherwise see in the din of my feed.</p>\n</li>\n<li>\n<p><strong>Spaces have felt very playful.</strong>  In so many ways, this reminds me of early social networking circa 2003 &#8212; or of first getting online a decade prior.  It just feels new, and fresh, and&#8230; fun!  For example, I was in one space where a security researcher that I revere was with their crew, all trying to find ways to hack the captioning.  (They made some interesting discoveries: because the captioning is done locally, they can actually reveal more about you than what you actually say!)  I was more or less laughing the whole time; it was delightful.</p>\n</li>\n<li>\n<p><strong>The content is golden.</strong>  If I have one complaint about Spaces, it&#8217;s that they aren&#8217;t publicly recorded &#8212; because there&#8217;s some great content here!  I am hoping that this gets added over time (obviously, opt-in and clear to all participants!), because speaking personally, I want to go back and listen to an awesome Space that I might have missed &#8212; and I want others to be able to do the same with any Space that I host.</p>\n</li>\n<li>\n<p><strong>People have been really nice!</strong>  Okay, this is a little one, but I think an essential one:  in every Space I&#8217;ve been in, the people have just been incredibly friendly and welcoming.  One of the challenges of the written word is that it&#8217;s too easy to be nasty:  our mirror neurons don&#8217;t fire when our damage is inflicted at a distance.  (Take it from the guy still trying to apologize for a Usenet comment from several decades ago!)  While it&#8217;s still obviously very early for Twitter Spaces, being in a spoken conversation makes us much more predisposed to empathy &#8212; and I&#8217;m optimistic that the medium will retain the decency that we have lost elsewhere, allowing us a venue to listen to and learn from other perspectives.   I also really like Twitter&#8217;s emphasis on safety &#8212; and I&#8217;m hopeful that the inevitable bad behavior that does crop up is taken care of pretty quickly.</p>\n</li>\n<li>\n<p><strong>Clubhouse is in trouble.</strong>  I have been in a couple of Spaces where Clubhouse comes up (indeed, one of the Spaces I was in was a security researcher reporting how poorly Clubhouse handled a pretty serious safety issue that she had found), and in all of those conversations, the tenor is more or less the same:  there was a brief moment last summer (especially, post George Floyd) when Clubhouse felt really important &#8212; profound, even &#8212; but their poor execution since has driven people away.  In this regard, my early social networking metaphor may be apt in more ways than one: Clubhouse feels like <a href=\"https://en.wikipedia.org/wiki/Friendster\">Friendster</a>.  And just as Friendster hit on something huge (social networking!) for the wrong reasons (the founder&#8217;s desire to find dates!), Clubhouse&#8217;s focus on listening to famous people feels misplaced.  (Speaking for myself, I am looking for conversations, not outtakes of <a href=\"https://en.wikipedia.org/wiki/Behind_the_Music\">Behind the Music</a>.)</p>\n</li>\n<li>\n<p><strong>Hosting has been rewarding.</strong>  So far, <a href=\"https://twitter.com/bcantrill/status/1386765936405872641\">I have hosted one Space</a>, convincing <a href=\"https://twitter.com/ahl\">Adam</a> to join me so I wouldn&#8217;t die alone.  I think it&#8217;s fair to say that Adam was somewhat skeptical going in, but came out seeing promise in the medium.  For example, one participant was dialing in from central Asia (where it was 4a!), and we ended up in a discussion on how insulated kids can become from the underlying mechanics of how computers actually work.  He decribed that growing up needing to rely on second-hand computers was an essential part of his own technical education &#8212; that having less made him need to understand more.  It was a moment that had everyone reflecting, and I&#8217;m honestly not sure how else that little interaction would have happened.</p>\n</li>\n</ul>\n<p>All in all, very positive and promising!  Of course, there are still lots of things to stub your toe on; this is still new, after all, and lots of stuff doesn&#8217;t work quite right.  And there&#8217;s also a lot to be figured out by those of us who will use the medium (reminder: retweets were invented by users, not by Twitter!).  For my part from a hosting perspective, I am going to take some inspiration from talk radio and experiment with both regularity and time-bounds:  Adam and I are going to host a Space again tomorrow (Monday) at 5p Pacific, keeping it again to about an hour.  (We appear to be aided in our time bounds last week by a memory leak that caused my app to abort after about an hour!)  So if you&#8217;re interested, drop on by &#8212; we&#8217;d love to hear what you have to say, which indeed is very much the whole point!</p>"
        }
      ],
      "wfw_commentrss": "http://dtrace.org/blogs/bmc/2021/05/02/twitter-spaces-a-few-weeks-in/feed/",
      "slash_comments": "0"
    }
  },
  {
    "blog": {
      "title": "Scholar's Stage",
      "by": "Tanner Greer",
      "url": "https://scholars-stage.org/",
      "feed": "https://scholars-stage.org/feed/",
      "description": "Essays of a westerner living in China. Unexpected sides of Chinese and\ngenerally non-Western politics and economics. A lot of book reviews\n(non-fiction).",
      "section": "Politics"
    },
    "entry": {
      "title": "A Guide Map for Reading the East Asian Canon",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://scholars-stage.org/feed/",
        "value": "A Guide Map for Reading the East Asian Canon"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://scholars-stage.org/a-guide-map-for-reading-the-east-asian-canon/"
        }
      ],
      "link": "https://scholars-stage.org/a-guide-map-for-reading-the-east-asian-canon/",
      "comments": "https://scholars-stage.org/a-guide-map-for-reading-the-east-asian-canon/#comments",
      "authors": [
        {
          "name": "T. Greer"
        }
      ],
      "author": "T. Greer",
      "author_detail": {
        "name": "T. Greer"
      },
      "published": "Fri, 01 Jul 2022 02:05:39 +0000",
      "published_parsed": [
        2022,
        7,
        1,
        2,
        5,
        39,
        4,
        182,
        0
      ],
      "tags": [
        {
          "term": "Books and Literature",
          "scheme": null,
          "label": null
        },
        {
          "term": "Culture",
          "scheme": null,
          "label": null
        },
        {
          "term": "History",
          "scheme": null,
          "label": null
        },
        {
          "term": "Japan",
          "scheme": null,
          "label": null
        },
        {
          "term": "The Middle Kingdom",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://scholars-stage.org/?p=3486",
      "guidislink": false,
      "summary": "<!-- wp:paragraph -->\n<p><strong>Readers may remember</strong> <a href=\"https://scholars-stage.org/a-non-western-canon-what-would-a-list-of-humanitys-100-greatest-writers-look-like/\">my stab at a global Great Books list</a>. Recently a reader contacted me asking for guidance: they wanted to read through the books on the \"East Asian\" section of that list, but did not believe he had the proper historical knowledge to understand or contextualize what they were reading. What do I recommend they read to make sense of the list?</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>What follows will not make sense if you have not looked at that original post. Here is what I told him:</p>\n<!-- /wp:paragraph -->",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://scholars-stage.org/feed/",
        "value": "<!-- wp:paragraph -->\n<p><strong>Readers may remember</strong> <a href=\"https://scholars-stage.org/a-non-western-canon-what-would-a-list-of-humanitys-100-greatest-writers-look-like/\">my stab at a global Great Books list</a>. Recently a reader contacted me asking for guidance: they wanted to read through the books on the \"East Asian\" section of that list, but did not believe he had the proper historical knowledge to understand or contextualize what they were reading. What do I recommend they read to make sense of the list?</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>What follows will not make sense if you have not looked at that original post. Here is what I told him:</p>\n<!-- /wp:paragraph -->"
      },
      "wfw_commentrss": "https://scholars-stage.org/a-guide-map-for-reading-the-east-asian-canon/feed/",
      "slash_comments": "1",
      "post-id": "3486"
    }
  },
  {
    "blog": {
      "title": "maya.land",
      "url": "https://maya.land/posts/",
      "feed": "https://maya.land/feed.xml",
      "description": "Carefully curated personal web space. Some posts were interesting\nto me, let's see how it goes",
      "section": "Uncategorized new blogs"
    },
    "entry": {
      "title": "three pages of linguistics paper that you’ve got to read",
      "title_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://maya.land/feed.xml",
        "value": "three pages of linguistics paper that you’ve got to read"
      },
      "links": [
        {
          "href": "https://maya.land/responses/2022/06/13/anne-cutler-linguistics.html",
          "rel": "alternate",
          "type": "text/html",
          "title": "three pages of linguistics paper that you’ve got to read"
        }
      ],
      "link": "https://maya.land/responses/2022/06/13/anne-cutler-linguistics.html",
      "published": "2022-06-13T00:00:00-07:00",
      "published_parsed": [
        2022,
        6,
        13,
        7,
        0,
        0,
        0,
        164,
        0
      ],
      "updated": "2022-06-13T00:00:00-07:00",
      "updated_parsed": [
        2022,
        6,
        13,
        7,
        0,
        0,
        0,
        164,
        0
      ],
      "id": "https://maya.land/responses/2022/06/13/anne-cutler-linguistics",
      "guidislink": false,
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://maya.land/responses/2022/06/13/anne-cutler-linguistics.html",
          "value": "<p>Really–even if you doubt me on it, it’s not want but <em>need</em>.</p>\n\n<p>Found on <a href=\"https://www.metafilter.com/195588/The-premise-of-the-paper-proves-itself\">Metafilter</a>, where a commenter replied that the author was <a href=\"https://en.wikipedia.org/wiki/Anne_Cutler\">Anne Cutler</a>, and that just this month she’d died. <em>Sentence stress and sentence comprehension</em> was the name of her freaking dissertation, so she really knew the game…</p>"
        }
      ],
      "summary": "Really–even if you doubt me on it, it’s not want but need.",
      "authors": [
        {
          "name": ""
        }
      ],
      "author_detail": {
        "name": ""
      },
      "author": "",
      "tags": [
        {
          "term": "responses",
          "scheme": null,
          "label": null
        },
        {
          "term": "bookmark",
          "scheme": null,
          "label": null
        },
        {
          "term": "linguistics",
          "scheme": null,
          "label": null
        }
      ],
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://maya.land/feed.xml",
        "value": "Really–even if you doubt me on it, it’s not want but need."
      }
    }
  }
]
